<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Coca-Cola Interview Prep | Security Engineer Portfolio</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body { background: #0a0a0f; color: #e0e0e0; font-family: 'Inter', system-ui, sans-serif; }
        .card { background: linear-gradient(145deg, #12121a, #1a1a2e); border: 1px solid #2a2a3e; }
        .coca-cola { background: linear-gradient(135deg, #1a0a0a 0%, #1a1a2e 100%); border: 1px solid #dc2626; }
        .behavioral { background: linear-gradient(135deg, #1a1a2e 0%, #1e1e3e 100%); border: 1px solid #8b5cf6; }
        .technical { background: linear-gradient(135deg, #0d1f0d 0%, #1a1a2e 100%); border: 1px solid #10b981; }
        .framework { background: linear-gradient(135deg, #1a1a0d 0%, #1a1a2e 100%); border: 1px solid #f59e0b; }
        .scenario { background: linear-gradient(135deg, #0d1a1a 0%, #1a1a2e 100%); border: 1px solid #06b6d4; }
        .memorize { background: linear-gradient(135deg, #1a0d1a 0%, #1a1a2e 100%); border: 1px solid #ec4899; }
        .diagram { background: #0a0a0f; border: 1px solid #2a2a3e; font-family: 'Courier New', monospace; }
        pre { background: #0d0d14 !important; border-radius: 8px; padding: 16px; overflow-x: auto; }
        .answer-box { background: rgba(0,0,0,0.3); border-radius: 8px; padding: 16px; }
        .gold-phrase { background: rgba(245, 158, 11, 0.1); border-left: 3px solid #f59e0b; padding: 8px 12px; margin: 8px 0; }
    </style>
</head>
<body class="min-h-screen">
    <main class="lg:ml-64 lg:pl-6 pt-14 lg:pt-0">
        <div class="max-w-5xl mx-auto px-6 py-12">
            <!-- Hero -->
            <section class="mb-12">
                <div class="flex items-center gap-2 text-red-500 mb-4">
                    <span class="text-2xl">ğŸ¥¤</span>
                    <span class="text-sm font-medium">Coca-Cola Canada Bottling Limited</span>
                </div>
                <h1 class="text-4xl font-bold text-white mb-4">Interview Prep - Coca-Cola</h1>
                <p class="text-xl text-gray-400 mb-6">Tailored answers for Security Engineer role at Coke Canada Bottling</p>
                
                <div class="coca-cola rounded-xl p-5 mb-6">
                    <h3 class="text-red-400 font-bold mb-3">ğŸ¯ Company Profile - Know This!</h3>
                    <div class="grid md:grid-cols-2 gap-4 text-sm">
                        <div>
                            <p class="text-gray-300"><strong>Company:</strong> Independent, family-owned Canadian bottler (since 2018)</p>
                            <p class="text-gray-300"><strong>Size:</strong> 6,000+ employees across Canada</p>
                            <p class="text-gray-300"><strong>Operations:</strong> 50+ distribution centers, 5 manufacturing plants</p>
                            <p class="text-gray-300"><strong>Environment:</strong> Hybrid IT + OT (manufacturing, SCADA, PLCs)</p>
                        </div>
                        <div>
                            <p class="text-gray-300"><strong>Stack:</strong> Microsoft (Azure, MDE, MDC, DLP), Fortinet NGFWs</p>
                            <p class="text-gray-300"><strong>Frameworks:</strong> NIST, ISO 27001, IEC 62443, CIS</p>
                            <p class="text-gray-300"><strong>Focus:</strong> Zero Trust, DevSecOps, IT/OT convergence</p>
                            <p class="text-gray-300"><strong>Culture:</strong> "Greatest Bottler, Best People" - values DEI</p>
                        </div>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- WHY COCA-COLA -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-red-500/20 flex items-center justify-center text-red-400">1</span>
                    Why Coca-Cola Canada Bottling?
                </h2>

                <div class="behavioral rounded-xl p-6 mb-4">
                    <p class="text-purple-400 font-bold mb-3">Q: Why do you want to work at Coca-Cola Canada Bottling?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "Three things drew me to this role. First, <strong>the tech stack alignment</strong>â€”you're using Microsoft Defender, Azure security, DLP, and Fortinet NGFWs, which directly matches my experience with MDE, Sentinel, Purview DLP, and firewall administration. I can contribute immediately without a long ramp-up.<br><br>
                            
                            Second, <strong>the IT/OT convergence challenge</strong>. Securing manufacturing plants and distribution centers alongside corporate IT is exactly the kind of complexity I want to grow into. I've studied OT security conceptsâ€”the Purdue model, IEC 62443, the priority shift from confidentiality to availabilityâ€”and I find it genuinely interesting. While my hands-on experience is on the IT side, I'm eager to learn OT security and contribute to bridging that gap. My IT security engineering skills in detection, monitoring, and automation would translate well once I understand the OT constraints.<br><br>
                            
                            Third, <strong>the engineering focus</strong>. This isn't just a monitoring roleâ€”it's about designing, implementing, and automating security controls. The job description mentions DevSecOps, CI/CD pipeline security, and automation with Python/PowerShell. That's where I want to grow. I want to build security infrastructure, not just watch dashboards.<br><br>
                            
                            Plus, Coke Canada is an independent, family-owned business with a strong culture. I've read about your commitment to sustainability and communityâ€”the electric trucks, the 100% recycled plastic initiative. That alignment with values matters to me for a long-term fit."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- TELL ME ABOUT YOURSELF -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-purple-500/20 flex items-center justify-center text-purple-400">2</span>
                    Tell Me About Yourself
                </h2>

                <div class="behavioral rounded-xl p-6 mb-4">
                    <p class="text-purple-400 font-bold mb-3">Full Version (75-90 seconds)</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I started my cybersecurity career as a SOC Analyst at Cognizant, where I worked primarily with Splunk for alert triage and incident investigations. That role gave me a strong foundation in detection logic, attacker behavior, and end-to-end incident response.<br><br>
                            
                            I then moved into a security engineering position at Infosys, working across Trellix HX/EX/NX and Symantec DLP. I handled agent deployments, upgrades, policy tuning, and malware investigation. I also participated in evaluating next-generation EDR/XDR platforms such as CrowdStrike, Carbon Black, and Cortex XDR, and contributed to the migration from Trellix to Cortex XDR.<br><br>
                            
                            After relocating to Canada, I joined a Siemens subsidiary. I initially worked on Cortex XDR agent rollouts, VM broker deployments, and developing XSOAR automations. Later, I transitioned to a major security modernization projectâ€”a hybrid environment with on-prem Windows servers moving into Azure. I supported the migration from RSA NetWitness and ESET to a cloud-native Microsoft ecosystem. My responsibilities included converting RSA correlation rules into KQL for Sentinel, onboarding MDE across endpoints and servers, managing the coexistence phase of legacy and new tools, and building Logic Apps automation.<br><br>
                            
                            Currently, I'm working on the migration from Symantec DLP to Microsoft Purview Endpoint DLP. I joined during the pilot phase, helped with simulation-mode testing, reduced false positives, and now I'm part of the enforcement rolloutâ€”implementing block/warn actions and coordinating phased deployment with business teams. The project is nearing completion.<br><br>
                            
                            Outside of work, I'm genuinely passionate about securityâ€”I don't just clock out and forget about it. I build personal projects to deepen my skills and contribute to the people around me. I've built an email security platform that my friends, family, and colleagues now use to check suspicious emails and phishing attempts. I've created malware investigation tools for analyzing samples. And I'm currently working on a bridge tool to help GRC teams and security engineers speak the same language. For me, building things is how I learn best, and I like that these projects actually help people. It's that curiosity and drive to solve problems that I'd bring to this role."
                        </p>
                    </div>
                </div>

                <div class="behavioral rounded-xl p-6 mb-4">
                    <p class="text-purple-400 font-bold mb-3">Short Version (50-60 seconds)</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I started as a SOC Analyst at Cognizant working with Splunk, which gave me a strong foundation in incident response. I then moved into security engineering at Infosys, where I worked with Trellix EDR, Symantec DLP, and contributed to the migration from Trellix to Cortex XDR.<br><br>
                            
                            After relocating to Canada, I joined a Siemens subsidiary. I've worked on Cortex XDR deployments, XSOAR automations, and led the migration from RSA NetWitness to Microsoft Sentinelâ€”converting correlation rules to KQL, onboarding MDE, and building Logic Apps playbooks. Currently, I'm completing the migration from Symantec DLP to Microsoft Purview.<br><br>
                            
                            Outside of work, I build personal security projectsâ€”an email security platform that friends and family actually use to check phishing emails, malware analysis tools, and a GRC-security bridge tool I'm developing now. Building things is how I learn, and I enjoy creating tools that genuinely help people. That curiosity and hands-on approach is what I'd bring to this role."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6">
                    <p class="text-emerald-400 font-bold mb-3">ğŸ› ï¸ Personal Projects & Initiative (Talking Points)</p>
                    <div class="answer-box">
                        <p class="text-gray-400 text-xs mb-3">Use these details if interviewer asks follow-up questions about your projects:</p>
                        <div class="grid md:grid-cols-3 gap-4 text-sm">
                            <div class="bg-black/20 rounded-lg p-3">
                                <p class="text-emerald-400 font-semibold mb-2">Email Security Platform</p>
                                <p class="text-gray-300 text-xs">"Built this to help non-technical people check if an email is suspicious. My friends, family, and colleagues actually use itâ€”they forward me suspicious emails or use the tool directly. It analyzes headers, checks sender reputation, identifies spoofing. Started as a learning project, now it's genuinely helping people avoid scams."</p>
                            </div>
                            <div class="bg-black/20 rounded-lg p-3">
                                <p class="text-emerald-400 font-semibold mb-2">Malware Investigation Tools</p>
                                <p class="text-gray-300 text-xs">"Personal toolkit I built to practice malware analysis. Automates hash lookups, sandbox submissions, IOC extraction. I use it to analyze samples I find interesting and share findings with colleagues who are into threat research. It's how I stay sharp outside of work."</p>
                            </div>
                            <div class="bg-black/20 rounded-lg p-3">
                                <p class="text-emerald-400 font-semibold mb-2">GRC-Security Bridge Tool</p>
                                <p class="text-gray-300 text-xs">"Currently building this one. The idea came from seeing how GRC teams and security engineers often talk past each otherâ€”different vocabularies, different priorities. This tool maps technical controls to compliance frameworks. Still in development, but I'm excited about the problem it solves."</p>
                            </div>
                        </div>
                        <div class="mt-4 p-3 bg-yellow-500/10 border border-yellow-500/30 rounded-lg">
                            <p class="text-yellow-400 text-xs"><strong>Why This Matters to Interviewers:</strong> "It shows I'm genuinely passionate about securityâ€”not just as a job, but as something I care about. Building tools is how I learn best, and the fact that people actually use what I create means I'm solving real problems, not just doing tutorials. That curiosity and builder mindset is what I'd bring to the team."</p>
                        </div>
                        <div class="mt-4 p-3 bg-emerald-500/10 border border-emerald-500/30 rounded-lg">
                            <p class="text-emerald-400 text-xs font-bold mb-2">ğŸ’¡ Pro Move: Invite Them to See Your Work</p>
                            <p class="text-gray-300 text-xs mb-2">It's absolutely appropriate to offer to show your projects. It demonstrates confidence and gives tangible proof of your skills. Here's how to phrase it naturally:</p>
                            <div class="bg-black/30 rounded p-2 mt-2">
                                <p class="text-gray-300 text-xs italic">"Actually, if you're interested, I'd be happy to share a link to the email security platform after our conversation. I'd genuinely appreciate any feedback or insights you might haveâ€”it's always valuable to get a security professional's perspective on how I could improve it."</p>
                            </div>
                            <p class="text-gray-400 text-xs mt-2"><strong>Why this works:</strong></p>
                            <ul class="text-gray-400 text-xs mt-1 space-y-1">
                                <li>â€¢ <strong>Shows confidence</strong> â€” you're proud enough to show your work</li>
                                <li>â€¢ <strong>Demonstrates humility</strong> â€” asking for feedback, not just showing off</li>
                                <li>â€¢ <strong>Creates engagement</strong> â€” gives them something tangible to remember you by</li>
                                <li>â€¢ <strong>Opens follow-up</strong> â€” natural reason to send a thank-you email with the link</li>
                                <li>â€¢ <strong>Proves you're real</strong> â€” anyone can claim projects, few can actually show them</li>
                            </ul>
                            <p class="text-yellow-400 text-xs mt-3"><strong>âš ï¸ Timing:</strong> Don't force it. Best moments are when they ask about your projects, or naturally at the end when they ask "Any questions for us?" You could say: "No questions, but I'd love to share my email security project if you're curious to see it."</p>
                        </div>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- CONFLICT STORY - MDE vs ESET -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-purple-500/20 flex items-center justify-center text-purple-400">3</span>
                    Conflict / Disagreement Stories
                </h2>

                <div class="behavioral rounded-xl p-6 mb-4">
                    <p class="text-purple-400 font-bold mb-3">Q: Tell me about a time you had conflict with a coworker or team.</p>
                    <p class="text-gray-500 text-xs mb-3">Story: MDE Agent Rollout vs Sysadmin (ESET Conflict)</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "During our Microsoft Defender for Endpoint rollout, I ran into significant pushback from the infrastructure team. We were migrating from ESET, and the lead sysadmin was resistant to deploying the MDE agent because he'd already seen performance issues with ESET and was concerned about running another EDR.<br><br>
                            
                            His argument was that ESET was 'good enough' and adding MDE would just create more overhead and potential conflicts. He also felt the security team was making decisions that impacted his servers without consulting infrastructure first.<br><br>
                            
                            Instead of escalating or forcing the issue, I took time to understand his actual concerns. It turned out the real worry wasn't MDE specificallyâ€”it was the historical pattern of security tools causing performance problems and him getting blamed when servers slowed down.<br><br>
                            
                            So I proposed a controlled approach: we'd start with a small pilot group of 10 non-critical servers, run both agents in coexistence mode temporarily, and I'd personally monitor CPU, memory, and disk I/O during the pilot. I also showed him the MDE resource consumption data from Microsoft's documentationâ€”typically 2-3% CPUâ€”and committed to documenting a clear rollback procedure if anything went wrong.<br><br>
                            
                            We ran the pilot for two weeks. The performance impact was minimal, and MDE actually caught a suspicious PowerShell execution that ESET missed. That result changed the conversation. The sysadmin became supportive, and we expanded the rollout with his team's full cooperation.<br><br>
                            
                            The lesson for me was that resistance often has an underlying reason that isn't immediately stated. By addressing the real concernâ€”accountability and performance impactâ€”rather than just pushing the technical decision, I turned a blocker into a partner."
                        </p>
                    </div>
                </div>

                <div class="behavioral rounded-xl p-6 mb-4">
                    <p class="text-purple-400 font-bold mb-3">Q: Tell me about a time you disagreed with a technical decision.</p>
                    <p class="text-gray-500 text-xs mb-3">Story: MDE Onboarding Script Issue</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "One disagreement I handled professionally was during our MDE rollout when Infrastructure wanted to rely solely on the golden image to deploy the MDE agent, without running the onboarding script on each server.<br><br>
                            
                            I pushed back because skipping the script meant every cloned machine would inherit the same AAD device ID, and in Defender that causes a severe issue: multiple servers appear as a single endpoint, telemetry overlaps, and DeviceProcessEvents basically collapse into one record. You lose individual visibility.<br><br>
                            
                            I demonstrated this using Sentinel queries where several 'different' servers were reporting under the same AAD ID with no actionable telemetry. After showing the gap, I worked with Infra to enforce a post-image onboarding step as mandatoryâ€”run the onboarding script per machine so each device gets a unique AAD identity.<br><br>
                            
                            Once we aligned on that process, new servers started reporting independently, telemetry stabilized, and it prevented what would have been a persistent blind spot across all future deployments. The key was presenting data, not just opinions."
                        </p>
                    </div>
                </div>

                <div class="behavioral rounded-xl p-6">
                    <p class="text-purple-400 font-bold mb-3">Q: Tell me about a time you handled pushback from another team.</p>
                    <p class="text-gray-500 text-xs mb-3">Story: Senior Analyst Feedback on Detection Rule</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "One example was when a senior threat analyst flagged that a detection rule I built in Sentinel had missed an event because my suppression logic was too aggressive and a key correlation condition didn't fire.<br><br>
                            
                            Instead of getting defensive, I walked through the telemetry with him, understood exactly where the correlation chain broke, and agreed that the suppression window needed refinement. I tuned the rule by tightening the matching logic, reducing the suppression duration, and validating it against historical samples.<br><br>
                            
                            After testing and redeploying, the analyst confirmed the fix and appreciated how quickly and calmly I incorporated the feedback. For me, it reinforced that good detection engineering is collaborativeâ€”feedback from experienced analysts makes the overall detection stack stronger."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- FRAMEWORK MAPPING -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-amber-500/20 flex items-center justify-center text-amber-400">4</span>
                    Framework Mapping Questions
                </h2>

                <div class="framework rounded-xl p-6 mb-4">
                    <p class="text-amber-400 font-bold mb-3">Q: How do you apply security frameworks to security controls?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "To align NIST or ISO with our security controls, I take the framework control list and map each requirement to an implemented security capabilityâ€”whether it's a tool, policy, or process.<br><br>
                            
                            For example:<br>
                            â€¢ <strong>ISO's data leakage prevention requirement</strong> â†’ maps to Purview DLP policies<br>
                            â€¢ <strong>NIST's anomaly detection controls</strong> â†’ maps to Sentinel analytics and UEBA<br>
                            â€¢ <strong>Access control requirements</strong> â†’ maps to Conditional Access and MFA in Entra ID<br>
                            â€¢ <strong>Privileged access management</strong> â†’ maps to Azure PIM or CyberArk<br>
                            â€¢ <strong>Vulnerability management</strong> â†’ maps to Defender TVM or Qualys<br><br>
                            
                            Where gaps exist, I document them, assign owners, and define remediation steps with timelines. This ensures complete top-down traceability from compliance requirements to operational controls. During audits, you can show exactly which tool or process satisfies each framework requirement."
                        </p>
                    </div>
                </div>

                <div class="framework rounded-xl p-6 mb-4">
                    <p class="text-amber-400 font-bold mb-3">Example: ISO A.12.4.1 â€“ Event Logging</p>
                    <div class="diagram rounded-lg p-4 mb-4">
                        <p class="text-cyan-400 text-xs mb-2">Framework Requirement â†’ Control Mapping</p>
                        <pre class="text-xs text-gray-300">
ISO A.12.4.1: "Events should be logged and logs retained to support investigations."

MAPPING TO CONTROLS:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ISO REQUIREMENT          â”‚  IMPLEMENTED CONTROL                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Event logging            â”‚  Sentinel data connectors:             â”‚
â”‚                           â”‚  - Azure AD / Entra ID                 â”‚
â”‚                           â”‚  - Microsoft 365                       â”‚
â”‚                           â”‚  - Microsoft Defender for Endpoint     â”‚
â”‚                           â”‚  - Fortinet NGFWs                      â”‚
â”‚                           â”‚  - AWS CloudTrail (if applicable)      â”‚
â”‚                           â”‚  - Zscaler access logs                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Log retention            â”‚  Log Analytics Workspace retention     â”‚
â”‚                           â”‚  (90 days hot, 2 years archive)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Investigation support    â”‚  - Sentinel hunting queries            â”‚
â”‚                           â”‚  - MDE Advanced Hunting                â”‚
â”‚                           â”‚  - Sysmon (if deployed on servers)     â”‚
â”‚                           â”‚  - Detection rules with entity mapping â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

OUTCOME: ISO A.12.4.1 is FULLY SATISFIED by:
         Sentinel + MDE + Firewalls + Retention Policies
                        </pre>
                    </div>
                </div>

                <div class="framework rounded-xl p-6 mb-4">
                    <p class="text-amber-400 font-bold mb-3">More Framework Mapping Examples</p>
                    <div class="overflow-x-auto">
                        <table class="w-full text-xs">
                            <thead>
                                <tr class="border-b border-gray-700">
                                    <th class="text-left py-2 px-3 text-amber-400">Framework Control</th>
                                    <th class="text-left py-2 px-3 text-gray-400">Requirement</th>
                                    <th class="text-left py-2 px-3 text-green-400">Mapped Tool/Process</th>
                                </tr>
                            </thead>
                            <tbody class="text-gray-300">
                                <tr class="border-b border-gray-800">
                                    <td class="py-2 px-3">NIST PR.AC-1</td>
                                    <td class="py-2 px-3">Identity management</td>
                                    <td class="py-2 px-3">Entra ID, Conditional Access, MFA</td>
                                </tr>
                                <tr class="border-b border-gray-800">
                                    <td class="py-2 px-3">NIST PR.AC-4</td>
                                    <td class="py-2 px-3">Least privilege</td>
                                    <td class="py-2 px-3">Azure PIM, RBAC, PAM solution</td>
                                </tr>
                                <tr class="border-b border-gray-800">
                                    <td class="py-2 px-3">NIST DE.AE-1</td>
                                    <td class="py-2 px-3">Anomaly detection</td>
                                    <td class="py-2 px-3">Sentinel UEBA, MDE behavior analytics</td>
                                </tr>
                                <tr class="border-b border-gray-800">
                                    <td class="py-2 px-3">NIST DE.CM-1</td>
                                    <td class="py-2 px-3">Network monitoring</td>
                                    <td class="py-2 px-3">NGFW logs, Sentinel, NDR</td>
                                </tr>
                                <tr class="border-b border-gray-800">
                                    <td class="py-2 px-3">ISO A.8.2.3</td>
                                    <td class="py-2 px-3">Data classification</td>
                                    <td class="py-2 px-3">Purview sensitivity labels, SITs</td>
                                </tr>
                                <tr class="border-b border-gray-800">
                                    <td class="py-2 px-3">ISO A.13.2.1</td>
                                    <td class="py-2 px-3">Data transfer policies</td>
                                    <td class="py-2 px-3">Purview DLP, CASB, email security</td>
                                </tr>
                                <tr class="border-b border-gray-800">
                                    <td class="py-2 px-3">ISO A.12.6.1</td>
                                    <td class="py-2 px-3">Vulnerability management</td>
                                    <td class="py-2 px-3">Defender TVM, Qualys, patch management</td>
                                </tr>
                                <tr class="border-b border-gray-800">
                                    <td class="py-2 px-3">IEC 62443</td>
                                    <td class="py-2 px-3">OT network segmentation</td>
                                    <td class="py-2 px-3">Purdue model, NGFW zones, industrial DMZ</td>
                                </tr>
                                <tr>
                                    <td class="py-2 px-3">CIS Control 8</td>
                                    <td class="py-2 px-3">Audit log management</td>
                                    <td class="py-2 px-3">Sentinel, Log Analytics, SIEM retention</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>

                <div class="framework rounded-xl p-6">
                    <p class="text-amber-400 font-bold mb-3">Q: How do you handle compliance gaps?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "When I identify a gap between framework requirements and implemented controls, I follow a structured approach:<br><br>
                            
                            <strong>1. Document the gap</strong> - What's required vs what exists today<br>
                            <strong>2. Assess the risk</strong> - What's the business impact of this gap?<br>
                            <strong>3. Identify remediation options</strong> - Tool, process, or compensating control<br>
                            <strong>4. Assign ownership</strong> - Who's responsible for remediation?<br>
                            <strong>5. Set timeline</strong> - When will it be resolved?<br>
                            <strong>6. Track to closure</strong> - Regular status updates until complete<br><br>
                            
                            For example, if ISO requires encryption at rest but we have unencrypted legacy databases, I'd document the gap, propose Azure SQL TDE or BitLocker depending on the system, assign it to the DBA or infrastructure team, and track it in our risk register until resolved."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- PURVIEW DLP DEEP DIVE -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-green-500/20 flex items-center justify-center text-green-400">5</span>
                    Purview DLP Migration (Your Flagship Project)
                </h2>

                <div class="memorize rounded-xl p-6 mb-4">
                    <h3 class="text-pink-400 font-bold mb-3">ğŸ§  High-Value Phrases to Memorize</h3>
                    <div class="space-y-2">
                        <div class="gold-phrase">
                            <p class="text-gray-300 text-sm">"Purview uses a <strong>condition-based model</strong>, whereas Symantec uses a <strong>rule-based model</strong>."</p>
                        </div>
                        <div class="gold-phrase">
                            <p class="text-gray-300 text-sm">"I translated Symantec rule logic into Purview conditions, SITs, and exceptions."</p>
                        </div>
                        <div class="gold-phrase">
                            <p class="text-gray-300 text-sm">"I validated each policy in <strong>Audit Mode</strong> before moving into enforcement."</p>
                        </div>
                        <div class="gold-phrase">
                            <p class="text-gray-300 text-sm">"We followed a structured, phased migration: <strong>Simulation â†’ Audit â†’ Enforcement</strong>."</p>
                        </div>
                        <div class="gold-phrase">
                            <p class="text-gray-300 text-sm">"During the dual-running phase, Symantec remained in enforcement while Purview ran in audit-only mode."</p>
                        </div>
                        <div class="gold-phrase">
                            <p class="text-gray-300 text-sm">"Tuning was primarily SIT confidence adjustments, exception creation, and aligning contextual logic."</p>
                        </div>
                    </div>
                </div>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-green-400 font-bold mb-3">Q: Walk me through your Purview Endpoint DLP migration end-to-end.</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "The Purview Endpoint DLP migration was a fully technical, end-to-end rebuild of our legacy Symantec rule base.<br><br>
                            
                            I started by translating Symantec's rule-based logic into Purview's condition-based model using SITs (Sensitive Information Types), EDM datasets, confidence levels, and proximity logic. Once the baseline policies were recreated, I ran both tools in parallelâ€”Symantec in enforcement and Purview in audit modeâ€”to compare behavioral parity and identify mismatches.<br><br>
                            
                            Most of the tuning work involved adjusting SIT confidence thresholds, refining EDM match requirements, and adding path, process, and domain exceptions to eliminate noise without weakening coverage. I validated every high-risk workflow, including Salesforce exports, Finance data transfers, and Engineering file movements, to ensure they behaved identically in both systems.<br><br>
                            
                            After the logic stabilized, I ran a controlled pilot, validated audit hits, fine-tuned remaining edge cases, and then executed a phased enforcement rollout before supporting the final decommissioning of Symantec.<br><br>
                            
                            By the end, we had fully rebuilt the DLP program with cleaner logic, tighter precision, and workflow-safe enforcement. False positives dropped by about 40% compared to the legacy system because of better tuning and Purview's native integration with the Microsoft ecosystem."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-green-400 font-bold mb-3">Q: How did you tune false positives in Purview?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "When I tuned false positives in Purview, I always started with root-cause analysis to understand why a policy firedâ€”whether it was an overly strict SIT confidence level, an EDM match that was too sensitive, or a workflow pattern that wasn't part of the original rule design.<br><br>
                            
                            My tuning approaches included:<br>
                            â€¢ <strong>SIT confidence adjustments</strong> - Lowering from High to Medium+High if catching too much<br>
                            â€¢ <strong>EDM threshold refinement</strong> - Adjusting match count requirements<br>
                            â€¢ <strong>Contextual exceptions</strong> - Path-based, process-based, or domain-based exclusions<br>
                            â€¢ <strong>Proximity logic</strong> - Ensuring related data elements appear together<br><br>
                            
                            I validated every change in audit mode and replayed historical data to see how the updated logic behaved under real conditions. After confirming clean, predictable alerting, I deployed the tuned policy, documented the update, and informed the SOC so they were aware of the expected detection pattern going forward."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6">
                    <p class="text-green-400 font-bold mb-3">Q: How did you ensure no workflow breakage during enforcement?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "To prevent workflow breakage during Purview DLP enforcement, I used a combined technical and business validation approach.<br><br>
                            
                            I first baseline-tested every policy in audit mode and compared Purview audit hits against Symantec's live enforcement to confirm behavioral parity. From there, I mapped all high-risk workflowsâ€”Salesforce exports, Finance data movements, Engineering file transfersâ€”and collected real samples from the business teams so I could tune SIT confidence, refine EDM match thresholds, and add exceptions only where they didn't weaken coverage.<br><br>
                            
                            Once the logic was stable, I ran a small pilot with representative users, monitored audit-only alerts for any anomalies, and worked directly with the business to validate that their workflows behaved exactly as expected.<br><br>
                            
                            After that, I expanded enforcement gradually, documented each exception in the register, and kept SOC and stakeholders updated so visibility stayed consistent. This combination of deep technical tuning and active business alignment ensured we reached full enforcement without disrupting a single critical workflow."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- SIEM/EDR MIGRATION -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-green-500/20 flex items-center justify-center text-green-400">6</span>
                    RSA â†’ Sentinel Migration
                </h2>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-green-400 font-bold mb-3">Q: Walk me through how you migrated RSA NetWitness correlation rules to Sentinel KQL analytics.</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "When we migrated from RSA NetWitness to Sentinel, I started by breaking down each RSA correlation rule, mapping the legacy meta keys to Sentinel's schema, and rewriting the logic in KQL with clean entity mapping and MITRE ATT&CK alignment.<br><br>
                            
                            As I translated the rules, I noticed a lot of duplication in the legacy environment, so I consolidated overlapping detections and categorized everything into three groups:<br>
                            â€¢ High-value built-in Sentinel rules (use as-is)<br>
                            â€¢ Built-ins requiring customization<br>
                            â€¢ Fully custom analytics (KQL from scratch)<br><br>
                            
                            I validated each rewritten rule using historical telemetry, tuned thresholds and suppression windows, and worked closely with the SOC to confirm the new detections behaved as expected. I also built a Sentinel workbook that monitored ingestion health, connector status, and telemetry completeness so we had a reliable view of detection readiness.<br><br>
                            
                            Between the deduplicated rule set, the improved KQL logic, and the visibility dashboards, we ended up with a cleaner, more accurate, and easier-to-maintain detection program than what existed in RSA. We actually finished about three months ahead of schedule."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6">
                    <p class="text-green-400 font-bold mb-3">Q: How do you design a high-fidelity detection rule in Sentinel?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "When I build a detection in Sentinel, I follow a structured 8-step process:<br><br>
                            
                            <strong>1. Define the threat</strong> - What attack technique? Map to MITRE ATT&CK<br>
                            <strong>2. Identify required logs</strong> - Confirm data sources are ingesting properly<br>
                            <strong>3. Build behavioral KQL logic</strong> - Focus on patterns, not just signatures<br>
                            <strong>4. Add noise controls</strong> - Thresholds, time windows, entity filters, allowlists<br>
                            <strong>5. Test with hunting queries</strong> - Run against historical data<br>
                            <strong>6. Deploy in audit mode</strong> - Measure FP/TP ratio<br>
                            <strong>7. Tune based on results</strong> - Refine suppression, thresholds<br>
                            <strong>8. Enable for alerting</strong> - Document and communicate to SOC<br><br>
                            
                            I always review the draft with the SOC to finalize expected alert patterns before enabling it in production. The goal is high fidelityâ€”alerts that are actionable, not noise."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- OT SECURITY (IMPORTANT FOR COKE) -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-cyan-500/20 flex items-center justify-center text-cyan-400">7</span>
                    OT Security (Critical for Manufacturing)
                </h2>

                <div class="scenario rounded-xl p-6 mb-4">
                    <p class="text-cyan-400 font-bold mb-3">Q: What experience do you have with OT/ICS security?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I'll be upfrontâ€”my hands-on experience is on the IT security side: SIEM, EDR, DLP, cloud security. I haven't directly worked with PLCs, SCADA systems, or industrial networks yet. However, OT security is an area I'm genuinely interested in and have been actively studying.<br><br>
                            
                            From my research and self-study, I understand the fundamental differences: OT prioritizes <strong>availability and safety</strong> over confidentiality. You can't just patch systems on a whimâ€”downtime costs millions, and some equipment runs legacy OS that vendors won't update. Active vulnerability scanning can crash PLCs, so you need passive monitoring approaches.<br><br>
                            
                            What I bring is strong IT security engineering skills that can support OT security efforts:<br>
                            â€¢ <strong>Network segmentation</strong> - I understand firewall zones and can help enforce IT/OT boundaries<br>
                            â€¢ <strong>Detection engineering</strong> - Building alerts for anomalous traffic patterns<br>
                            â€¢ <strong>Incident response</strong> - IR principles apply, though containment strategies differ<br>
                            â€¢ <strong>Collaboration mindset</strong> - I'd lean heavily on OT engineers who know the equipment<br><br>
                            
                            I'm familiar with frameworks like IEC 62443 and the Purdue model from studying, and I understand protocols like Modbus and EtherNet/IP at a conceptual level. I see this role as an opportunity to learn OT security properly while contributing my IT security expertise from day one."
                        </p>
                    </div>
                </div>

                <div class="scenario rounded-xl p-6">
                    <p class="text-cyan-400 font-bold mb-3">Q: How would you approach securing a manufacturing plant network?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "Based on my research and studying OT security frameworks, I'd approach this methodicallyâ€”but I want to be clear that I'd need to learn from your OT team and understand your specific environment first.<br><br>
                            
                            From what I've studied, the Purdue model provides a solid segmentation framework:<br><br>
                            
                            <strong>Level 5 (Enterprise)</strong> - Corporate IT, where my experience is strongest<br>
                            <strong>Level 4 (Site Business)</strong> - Historians, reporting servers<br>
                            <strong>Level 3.5 (Industrial DMZ)</strong> - Critical boundary I'd focus on<br>
                            <strong>Level 3 (Site Operations)</strong> - OT servers, engineering workstations<br>
                            <strong>Level 2 (Area Control)</strong> - HMIs, SCADA<br>
                            <strong>Level 1 (Basic Control)</strong> - PLCs, RTUs<br>
                            <strong>Level 0 (Physical)</strong> - Sensors, actuators<br><br>
                            
                            The principle is that traffic should only flow between adjacent levels. The industrial DMZ is where IT and OT meet, and that's where I could contribute immediatelyâ€”helping enforce boundaries using firewall rules and monitoring for policy violations.<br><br>
                            
                            For OT-specific monitoring, I know tools like Claroty, Nozomi, or Dragos are purpose-built for passive network analysis without disrupting equipment. I'd want to learn how those integrate with the SIEM and what detection use cases make sense for your environment.<br><br>
                            
                            Honestly, I'd start by listening and learning from plant operations teams. They know what's critical, what can't be touched, and where the real risks are. My job would be to bring security engineering discipline while respecting operational constraints."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- COMMON SCENARIOS -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-cyan-500/20 flex items-center justify-center text-cyan-400">8</span>
                    Scenario Questions
                </h2>

                <div class="scenario rounded-xl p-6 mb-4">
                    <p class="text-cyan-400 font-bold mb-3">Q: A business-critical app is being blocked by ASRâ€”what do you do?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I follow a controlled response:<br><br>
                            
                            <strong>1. Validate</strong> - Confirm it's truly ASR blocking (check event data, block reason)<br>
                            <strong>2. Assess criticality</strong> - How urgent? Is production impacted?<br>
                            <strong>3. Reproduce and confirm FP</strong> - Verify it's a false positive, not masking risky behavior<br>
                            <strong>4. Add targeted exclusion</strong> - Path/process/hash, not disabling the entire rule<br>
                            <strong>5. Document</strong> - Business justification, risk assessment, approval<br>
                            <strong>6. Monitor</strong> - Watch for potential abuse of the exception<br>
                            <strong>7. Revalidate later</strong> - Periodic review to see if exclusion is still needed<br><br>
                            
                            The key is adding the minimum exception necessary to unblock the workflow without weakening the overall protection."
                        </p>
                    </div>
                </div>

                <div class="scenario rounded-xl p-6 mb-4">
                    <p class="text-cyan-400 font-bold mb-3">Q: How do you handle telemetry gaps or ingestion failures?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "When I notice telemetry gaps, my troubleshooting process is:<br><br>
                            
                            <strong>1. Validate the gap</strong> - Run KQL against Heartbeat table and source tables to confirm stale timestamps<br>
                            <strong>2. Identify scope</strong> - Is it one connector, one region, or widespread?<br>
                            <strong>3. Check the ingestion path</strong> - Connector status, DCR configuration, agent health<br>
                            <strong>4. Coordinate with relevant team</strong> - Cloud team for AWS/Azure issues, Infra for agent issues<br>
                            <strong>5. Fix root cause</strong> - Reconfigure DCR, restart connector, fix agent deployment<br>
                            <strong>6. Validate recovery</strong> - Confirm data flowing with real-time and historical queries<br>
                            <strong>7. Add monitoring</strong> - Create workbook tile or Logic App alert for this failure mode<br><br>
                            
                            I actually built a Sentinel workbook during our migration that visualizes ingestion health, connector status, and MDE device health so we can catch gaps within minutes rather than hours."
                        </p>
                    </div>
                </div>

                <div class="scenario rounded-xl p-6">
                    <p class="text-cyan-400 font-bold mb-3">Q: What would you improve if you joined our team?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I'd start by understanding your current state before proposing changes. But based on what I know about the role, areas I'd focus on:<br><br>
                            
                            <strong>1. Detection quality</strong> - Review existing analytics for noise, tune high-FP rules, add behavior-based detections aligned to MITRE<br><br>
                            
                            <strong>2. Telemetry completeness</strong> - Validate coverage across endpoints, identity, and cloud. Build dashboards to visualize gaps<br><br>
                            
                            <strong>3. Automation</strong> - Identify repetitive tasks that can be scripted. Agent health monitoring, compliance reporting, alert enrichment<br><br>
                            
                            <strong>4. Learn OT security</strong> - This is an area I want to grow in. I'd work with the OT team to understand the manufacturing environment, learn what monitoring makes sense, and figure out how I can contribute from the IT/OT boundary<br><br>
                            
                            <strong>5. DevSecOps integration</strong> - If not already mature, help integrate security scanning into CI/CD pipelines<br><br>
                            
                            I'd do this incrementally, showing value quickly on IT security while learning the OT side."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- QUESTIONS TO ASK -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-pink-500/20 flex items-center justify-center text-pink-400">9</span>
                    Questions to Ask Them
                </h2>

                <div class="memorize rounded-xl p-6">
                    <div class="grid md:grid-cols-2 gap-6">
                        <div>
                            <h4 class="text-white font-medium mb-2">About the Role</h4>
                            <ul class="text-gray-400 text-sm space-y-1">
                                <li>â€¢ What does success look like in the first 90 days?</li>
                                <li>â€¢ How is the team structured? Who would I work most closely with?</li>
                                <li>â€¢ What's the split between proactive engineering vs reactive operations?</li>
                                <li>â€¢ What are the biggest security challenges facing Coke Canada right now?</li>
                            </ul>
                        </div>
                        <div>
                            <h4 class="text-white font-medium mb-2">About the Tech</h4>
                            <ul class="text-gray-400 text-sm space-y-1">
                                <li>â€¢ How mature is the IT/OT security integration currently?</li>
                                <li>â€¢ What's the current state of DevSecOps adoption?</li>
                                <li>â€¢ Are there any major security initiatives planned for this year?</li>
                                <li>â€¢ What tools or processes are you looking to improve or replace?</li>
                            </ul>
                        </div>
                        <div>
                            <h4 class="text-white font-medium mb-2">About Growth</h4>
                            <ul class="text-gray-400 text-sm space-y-1">
                                <li>â€¢ What learning and certification opportunities are available?</li>
                                <li>â€¢ How does the team handle knowledge sharing?</li>
                                <li>â€¢ What career progression paths exist within the security team?</li>
                            </ul>
                        </div>
                        <div>
                            <h4 class="text-white font-medium mb-2">Closing</h4>
                            <ul class="text-gray-400 text-sm space-y-1">
                                <li>â€¢ Is there anything about my background that gives you pause?</li>
                                <li>â€¢ What are the next steps in the interview process?</li>
                                <li>â€¢ When are you looking to make a decision?</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- TECHNICAL DEEP DIVE - NGFW -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-green-500/20 flex items-center justify-center text-green-400">11</span>
                    Technical Deep Dive: Next-Generation Firewalls
                </h2>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-green-400 font-bold mb-3">Q1: Walk me through how you would design and implement a firewall rule change process that balances security requirements with business agility.</p>
                    <p class="text-gray-500 text-xs mb-3">What they're assessing: Change management, risk assessment, operational workflows</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "At my current role, we follow a structured change management process for firewall rules that I helped refine. Here's how I approach it:<br><br>
                            
                            <strong>1. Request & Justification</strong><br>
                            Every change starts with a formal request through our ticketing system. The requester documents business justification, source/destination, ports, and expected duration. This creates an audit trail and forces people to think through what they actually need.<br><br>
                            
                            <strong>2. Security Review</strong><br>
                            I review each request against least privilege principles. I ask: Is this the minimum access needed? Can we use application-level rules instead of port-based? Are we opening anything to the internet that shouldn't be? I push back on overly broad requests like 'any-to-any' rules.<br><br>
                            
                            <strong>3. Validation & Testing</strong><br>
                            Before implementing in production, I validate the rule logic won't conflict with existing policies. On Fortinet, I use the policy lookup tool to check for conflicts. For high-risk changes, we test in a maintenance window first.<br><br>
                            
                            <strong>4. Implementation with Rollback Plan</strong><br>
                            I always document the current state before making changes so I can quickly rollback if something breaks. For critical systems, I coordinate with the application owner to test immediately after the change.<br><br>
                            
                            <strong>5. Review & Cleanup</strong><br>
                            Temporary rules get expiration dates. I schedule quarterly reviews to identify unused rules using traffic logs. Stale rules are security debtâ€”they accumulate if you don't actively clean them up."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-green-400 font-bold mb-3">Q2: You notice unusual traffic patterns that bypass traditional firewall rules. How would you investigate and respond using NGFW capabilities?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "This is where the 'next-gen' capabilities really matter. Here's my investigation approach:<br><br>
                            
                            <strong>1. Application Identification</strong><br>
                            First, I'd check if the traffic is using application tunneling or port obfuscation. NGFWs like Fortinet can identify applications regardless of portâ€”so even if something is running on port 443, it'll show if it's actually HTTPS, SSH-over-HTTPS, or something else entirely. I'd look at the application control logs to see what's being identified.<br><br>
                            
                            <strong>2. SSL/TLS Inspection Review</strong><br>
                            If traffic is encrypted, it could be creating blind spots. I'd check if SSL inspection is enabled for that traffic flow. Sometimes legitimate apps break with inspection, so there may be bypass rules that attackers could exploit. I'd review the decrypt policy exceptions.<br><br>
                            
                            <strong>3. Deep Packet Inspection</strong><br>
                            I'd enable detailed logging and packet capture for the suspicious traffic to analyze payload patterns. Looking for signatures of known tunneling tools like DNS tunneling, ICMP tunneling, or HTTP-over-DNS.<br><br>
                            
                            <strong>4. Threat Intelligence Correlation</strong><br>
                            Cross-reference the destination IPs and domains against our threat intelligence feeds. Fortinet's FortiGuard provides real-time threat intel that can identify C2 domains or known malicious infrastructure.<br><br>
                            
                            <strong>5. Immediate Response</strong><br>
                            If I confirm malicious activity, I'd implement a temporary block while investigating further. Then I'd pivot to our EDR (MDE) to check the source endpoint for compromise indicators. Finally, document everything and create a permanent policy based on findings."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6">
                    <p class="text-green-400 font-bold mb-3">Q3: Explain your approach to troubleshooting asymmetric routing issues that are causing firewall state table problems in a multi-site environment.</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "Asymmetric routing is tricky because stateful firewalls expect to see both sides of a conversation. Here's how I'd troubleshoot:<br><br>
                            
                            <strong>1. Identify the Problem</strong><br>
                            First, confirm it's actually asymmetric routing. Symptoms include random connection drops, TCP resets, and firewall logs showing 'no matching session' or 'asymmetric traffic dropped.' I'd use packet captures on both the firewall and endpoints to trace the traffic path in both directions.<br><br>
                            
                            <strong>2. Analyze the Routing</strong><br>
                            Check routing tables across all sites and network devices. In multi-site environments, this often happens when there are multiple paths to the same destinationâ€”like when you have dual ISPs or MPLS + internet backup. Traffic goes out one path but returns via another, hitting a different firewall that doesn't have the session state.<br><br>
                            
                            <strong>3. Solutions I'd Consider</strong><br>
                            â€¢ <strong>Fix the routing</strong> - Adjust routing metrics so traffic is symmetric. This is the cleanest solution if feasible.<br>
                            â€¢ <strong>Stateful failover clustering</strong> - If using HA firewall pairs, ensure session state is synchronized between them.<br>
                            â€¢ <strong>Asymmetric routing support</strong> - Some NGFWs have settings to tolerate asymmetric traffic, though this weakens security posture.<br>
                            â€¢ <strong>Source-based routing</strong> - Use policy-based routing to ensure return traffic follows the same path.<br><br>
                            
                            <strong>4. Validate & Document</strong><br>
                            After implementing the fix, I'd test affected applications thoroughly and monitor the firewall state table for a few days to confirm the issue is resolved. Then document the root cause and solution for future reference."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- TECHNICAL DEEP DIVE - CLOUD SECURITY -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-blue-500/20 flex items-center justify-center text-blue-400">12</span>
                    Technical Deep Dive: Cloud Security & Azure
                </h2>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-blue-400 font-bold mb-3">Q4: How would you design a security architecture for a multi-tier application migrating to Azure, considering network segmentation, identity management, and data protection?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I've worked on securing Azure environments at my current role, particularly around integrating Microsoft Sentinel and Defender for Cloud. Here's my architecture approach:<br><br>
                            
                            <strong>Network Segmentation</strong><br>
                            â€¢ Separate VNets for each tier (web, app, data) with controlled peering<br>
                            â€¢ NSGs at the subnet level with explicit deny rulesâ€”only allow what's needed<br>
                            â€¢ Application Security Groups (ASGs) to group VMs by function rather than managing individual IPs<br>
                            â€¢ Azure Private Link for PaaS services so database traffic never touches the public internet<br>
                            â€¢ Azure Firewall or NVA for centralized egress filtering and logging<br><br>
                            
                            <strong>Identity Management</strong><br>
                            â€¢ Entra ID (Azure AD) as the identity provider with Conditional Access policies<br>
                            â€¢ MFA enforced for all users, phishing-resistant methods for admins<br>
                            â€¢ Managed Identities for application-to-service authenticationâ€”no credentials stored in code<br>
                            â€¢ Azure PIM for just-in-time privileged access with approval workflows<br>
                            â€¢ Regular access reviews to catch permission creep<br><br>
                            
                            <strong>Data Protection</strong><br>
                            â€¢ Azure Key Vault for secrets, keys, and certificates with RBAC<br>
                            â€¢ Encryption at rest (default) and in transit (TLS 1.2+)<br>
                            â€¢ Azure SQL TDE for database encryption<br>
                            â€¢ Purview for data classification and DLP if sensitive data is involved<br><br>
                            
                            <strong>Monitoring & Detection</strong><br>
                            â€¢ Microsoft Defender for Cloud for CSPM and workload protection<br>
                            â€¢ Sentinel for SIEM with data connectors for all Azure services<br>
                            â€¢ Diagnostic settings enabled on everything, logs flowing to Log Analytics"
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-blue-400 font-bold mb-3">Q5: Describe your experience with Azure Policy and how you would use it to enforce security compliance across multiple subscriptions.</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I've worked with Azure Policy for enforcing security baselines and preparing for compliance audits. Here's my approach:<br><br>
                            
                            <strong>My Experience</strong><br>
                            At Siemens, we use Azure Policy to enforce security standards across our Azure subscriptions. I've created custom policies for things like requiring specific NSG rules, enforcing encryption, and blocking public blob access.<br><br>
                            
                            <strong>Implementation Strategy</strong><br>
                            â€¢ <strong>Start in Audit Mode</strong> - Never deploy in 'Deny' mode first. I always start with 'Audit' to understand the current compliance state and identify what would break.<br>
                            â€¢ <strong>Use Management Groups</strong> - Apply policies at the management group level so they inherit down to all subscriptions. This ensures consistency without manually applying to each subscription.<br>
                            â€¢ <strong>Policy Initiatives</strong> - Bundle related policies together. I use the built-in initiatives like 'Azure Security Benchmark' as a starting point, then add custom policies for organization-specific requirements.<br><br>
                            
                            <strong>Key Policies I've Implemented</strong><br>
                            â€¢ Require MDE extension on all VMs<br>
                            â€¢ Deny public IP addresses on VMs (with exceptions for approved jump boxes)<br>
                            â€¢ Require diagnostic settings on all resources<br>
                            â€¢ Enforce minimum TLS versions<br>
                            â€¢ Require specific tags for cost allocation and ownership<br><br>
                            
                            <strong>Exception Management</strong><br>
                            Real environments need exceptions. I create exemptions with documented business justification, owner, and expiration date. These get reviewed quarterly. The goal is security, not blocking legitimate business needs."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6">
                    <p class="text-blue-400 font-bold mb-3">Q6: What are the key differences between securing IaaS versus PaaS resources in Azure, and how does your security approach change?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "This is fundamentally about the shared responsibility model, and it changes my focus significantly:<br><br>
                            
                            <strong>IaaS (VMs) - More Control, More Responsibility</strong><br>
                            With IaaS, I'm responsible for everything from the OS up:<br>
                            â€¢ OS hardening and CIS benchmark compliance<br>
                            â€¢ Patch management (we use Azure Update Management)<br>
                            â€¢ Endpoint protection (MDE agent deployment)<br>
                            â€¢ Host-based firewall rules<br>
                            â€¢ Antimalware and monitoring agents<br>
                            â€¢ Disk encryption configuration<br><br>
                            
                            At my current role, I manage the MDE deployment across our Azure VMs. It's similar to on-premâ€”I need to ensure agents are healthy, policies are applied, and baselines are enforced.<br><br>
                            
                            <strong>PaaS (App Services, Azure SQL, etc.) - Different Focus</strong><br>
                            Microsoft handles infrastructure security, so I focus on:<br>
                            â€¢ Access control and authentication (Managed Identities, RBAC)<br>
                            â€¢ Network isolation (Private Endpoints, VNet integration)<br>
                            â€¢ Service-specific security settings (SQL firewall rules, App Service access restrictions)<br>
                            â€¢ Data protection and encryption configuration<br>
                            â€¢ Logging and monitoring setup<br><br>
                            
                            <strong>Practical Example</strong><br>
                            For a VM running SQL Server: I handle OS patching, SQL patching, firewall rules, backup configuration, TDE setup, and monitoring.<br>
                            For Azure SQL PaaS: Microsoft handles all that infrastructure. I focus on firewall rules, Private Link, TDE keys in Key Vault, auditing, and threat detection settings.<br><br>
                            
                            The security effort doesn't decrease with PaaSâ€”it shifts. You trade operational overhead for configuration discipline."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- TECHNICAL DEEP DIVE - DEVSECOPS -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-purple-500/20 flex items-center justify-center text-purple-400">13</span>
                    Technical Deep Dive: DevSecOps & CI/CD Security
                </h2>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-purple-400 font-bold mb-3">Q7: How would you integrate security scanning into a CI/CD pipeline without significantly impacting deployment velocity?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I'll be honestâ€”DevSecOps is an area I'm actively building experience in. I understand the principles and have implemented some aspects, but I'm eager to go deeper at Coke Canada. Here's my approach:<br><br>
                            
                            <strong>Shift Left Without Breaking Flow</strong><br>
                            The key is running the right scans at the right stages:<br>
                            â€¢ <strong>Pre-commit</strong> - IDE plugins for developers to catch issues before code even hits the repo. Fast, immediate feedback.<br>
                            â€¢ <strong>Pull Request</strong> - SAST (Static Analysis) runs automatically. Block merge only for critical/high findings; warn on medium/low.<br>
                            â€¢ <strong>Build Stage</strong> - Dependency scanning (SCA) to catch vulnerable libraries. This is fast and catches most third-party risks.<br>
                            â€¢ <strong>Staging</strong> - DAST (Dynamic) scans run against deployed app. These take longer, so run in parallel or off-hours.<br><br>
                            
                            <strong>Balancing Speed and Security</strong><br>
                            â€¢ Use risk-based thresholdsâ€”don't block everything. Critical vulnerabilities block deployment; medium/low get tracked and fixed on schedule.<br>
                            â€¢ Cache scan results to avoid redundant scanning of unchanged code.<br>
                            â€¢ Run expensive scans in parallel with other pipeline stages, not serially.<br>
                            â€¢ Give developers clear, actionable feedbackâ€”not just 'vulnerability found' but 'here's how to fix it.'<br><br>
                            
                            <strong>What I'd Want to Learn at Coke Canada</strong><br>
                            I'd be interested in how your DevSecOps maturity is structuredâ€”what tools are in place, where the gaps are, and how I can contribute to improving the program."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-purple-400 font-bold mb-3">Q8: Explain how you would implement infrastructure-as-code security scanning and policy enforcement for Terraform or ARM templates.</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "IaC security is critical because misconfigurations at the infrastructure level can be catastrophic. Here's my approach:<br><br>
                            
                            <strong>Multi-Stage Scanning</strong><br>
                            â€¢ <strong>Pre-commit</strong> - Tools like tfsec or Checkov run locally. Developers catch issues before pushing. Fast feedback loop.<br>
                            â€¢ <strong>PR Validation</strong> - Automated scan in CI pipeline. Results posted as PR comments so reviewers see security findings alongside code changes.<br>
                            â€¢ <strong>Deployment Gate</strong> - Final validation against organizational policies before terraform apply. This is the hard stop.<br>
                            â€¢ <strong>Post-Deployment</strong> - Continuous compliance monitoring. Azure Policy catches drift if someone makes manual changes.<br><br>
                            
                            <strong>Tools I'm Familiar With</strong><br>
                            â€¢ Checkov - Open source, comprehensive rules for Terraform, ARM, CloudFormation<br>
                            â€¢ tfsec - Terraform-specific, very fast<br>
                            â€¢ Azure Policy - Native enforcement for ARM deployments<br>
                            â€¢ Defender for Cloud - Provides IaC scanning as part of DevOps security<br><br>
                            
                            <strong>Common Misconfigurations I'd Catch</strong><br>
                            â€¢ Storage accounts with public access enabled<br>
                            â€¢ VMs with public IPs and no NSG<br>
                            â€¢ Databases without encryption or with overly permissive firewall rules<br>
                            â€¢ Resources missing required tags (ownership, cost center)<br>
                            â€¢ Hardcoded secrets in templates (this happens more than it should)<br><br>
                            
                            The goal is catching these before deployment, not after a security incident."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6">
                    <p class="text-purple-400 font-bold mb-3">Q9: A development team wants to deploy a new microservice but security scanning is showing multiple vulnerabilities. How do you handle this conflict?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "This is a common scenario, and how you handle it defines whether security is seen as a partner or a blocker. Here's my approach:<br><br>
                            
                            <strong>1. Triage Together</strong><br>
                            I'd schedule a quick call with the dev team to review findings togetherâ€”not just email them a report. Walk through each vulnerability: Is it a false positive? Is it actually exploitable in their deployment context? Categorize by actual risk, not just CVSS score.<br><br>
                            
                            <strong>2. Identify Quick Wins</strong><br>
                            Often, some vulnerabilities are easy fixesâ€”dependency updates, configuration changes. Get those done immediately. For the harder ones, understand the timeline and effort required.<br><br>
                            
                            <strong>3. Risk-Based Decision</strong><br>
                            If critical/high vulnerabilities remain:<br>
                            â€¢ Can we add compensating controls? Network segmentation, WAF rules, enhanced monitoring?<br>
                            â€¢ What's the business impact of delaying deployment?<br>
                            â€¢ Can we do a limited deployment (internal only, single region) while fixing issues?<br><br>
                            
                            <strong>4. Document Risk Acceptance</strong><br>
                            If the business decides to proceed despite risks, I document it formallyâ€”what the risk is, what compensating controls are in place, who approved it, and the committed remediation timeline. This isn't about covering my own back; it's about making the risk visible and tracked.<br><br>
                            
                            <strong>5. Follow Through</strong><br>
                            I'd add the remediation items to my tracking system and follow up. Security debt, like technical debt, compounds if you don't actively manage it."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- TECHNICAL DEEP DIVE - PAM -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-yellow-500/20 flex items-center justify-center text-yellow-400">14</span>
                    Technical Deep Dive: Privileged Access Management
                </h2>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-yellow-400 font-bold mb-3">Q10: Walk me through your approach to implementing a PAM solution for a hybrid environment with both on-premises and cloud infrastructure.</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I've worked with Azure PIM for cloud privileged access, and I understand the principles that apply to broader PAM implementation. Here's how I'd approach a hybrid environment:<br><br>
                            
                            <strong>Phase 1: Discovery</strong><br>
                            Before implementing anything, you need to know what you're protecting. Identify all privileged accounts:<br>
                            â€¢ Local admin accounts on servers<br>
                            â€¢ Domain admin and service accounts in AD<br>
                            â€¢ Cloud admin roles (Azure, M365)<br>
                            â€¢ Database admin accounts<br>
                            â€¢ Network device credentials<br>
                            This always reveals more accounts than anyone expects.<br><br>
                            
                            <strong>Phase 2: Prioritized Onboarding</strong><br>
                            Start with the highest-risk accountsâ€”Domain Admins, Azure Global Admins, database SAs. Implement:<br>
                            â€¢ Password vaulting with automatic rotation<br>
                            â€¢ Session recording for audit trail<br>
                            â€¢ Just-in-time access with approval workflows<br>
                            Then expand to service accounts, application credentials, and eventually all privileged access.<br><br>
                            
                            <strong>Phase 3: Integrate with Identity</strong><br>
                            For hybrid environments, integrate PAM with both on-prem AD and Entra ID. This gives you:<br>
                            â€¢ Single pane of glass for privileged access requests<br>
                            â€¢ Consistent policy enforcement across environments<br>
                            â€¢ Unified audit logs<br><br>
                            
                            <strong>Azure PIM Specifically</strong><br>
                            I've configured Azure PIM for just-in-time elevation of Azure roles. Key settings I implement:<br>
                            â€¢ Time-bound role assignments (4-8 hours max)<br>
                            â€¢ MFA required for activation<br>
                            â€¢ Justification required<br>
                            â€¢ Approval workflow for highly sensitive roles<br>
                            â€¢ Regular access reviews"
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-yellow-400 font-bold mb-3">Q11: How would you handle a scenario where a critical application requires a shared privileged account but the development team resists PAM implementation due to workflow concerns?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "This is very similar to the challenges I faced during the MDE deployment at Siemens. The infrastructure team had legitimate concerns about workflow disruption. Here's how I'd handle it:<br><br>
                            
                            <strong>1. Listen First</strong><br>
                            Meet with the team to understand their specific concerns. Usually it's:<br>
                            â€¢ 'We need quick access during incidents'<br>
                            â€¢ 'Automated jobs use this account and can't handle check-out/check-in'<br>
                            â€¢ 'We've always done it this way'<br>
                            Understanding the real workflow helps me design a solution that works.<br><br>
                            
                            <strong>2. Address Each Concern</strong><br>
                            â€¢ <strong>Quick access needs</strong> - Configure emergency/break-glass procedures with expedited approval. Or pre-staged sessions for incident response.<br>
                            â€¢ <strong>Automated jobs</strong> - Use API-based credential retrieval so scripts can pull credentials programmatically without human checkout. This actually improves security because credentials rotate without breaking automation.<br>
                            â€¢ <strong>Change resistance</strong> - This is where pilots help. Show them it works, address issues, build confidence.<br><br>
                            
                            <strong>3. Pilot with Their Input</strong><br>
                            Deploy to a subset of their systems first, with their team involved in testing. Adjust policies based on real feedback. Document what works.<br><br>
                            
                            <strong>4. Make Security Invisible</strong><br>
                            The best security doesn't feel like friction. If I can implement PAM in a way that's actually easier than the current processâ€”single sign-on, auto-credential injection, no more password resetsâ€”they'll adopt it willingly."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6">
                    <p class="text-yellow-400 font-bold mb-3">Q12: Explain your strategy for managing privileged access to cloud platforms like Azure, where traditional PAM solutions may not fully apply.</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "Cloud PAM is different because you're managing roles and permissions, not just credentials. Here's my strategy using Azure-native tools:<br><br>
                            
                            <strong>Azure PIM for Role Elevation</strong><br>
                            This is my primary tool for Azure privileged access:<br>
                            â€¢ Users have 'eligible' roles, not 'active' roles<br>
                            â€¢ When they need access, they activate through PIM with justification<br>
                            â€¢ Access is time-bound (I typically set 4-8 hours maximum)<br>
                            â€¢ MFA is required at activation<br>
                            â€¢ For sensitive roles like Global Admin, I require approval<br><br>
                            
                            <strong>Managed Identities for Applications</strong><br>
                            This eliminates credential management entirely for app-to-service authentication. Instead of storing a connection string with credentials, the app authenticates using its Azure identity. No passwords to rotate, no secrets to leak.<br><br>
                            
                            <strong>Azure Key Vault for Remaining Secrets</strong><br>
                            For credentials that must exist (third-party integrations, legacy systems):<br>
                            â€¢ Store in Key Vault with RBAC<br>
                            â€¢ Enable soft-delete and purge protection<br>
                            â€¢ Set up access policies that limit who can retrieve secrets<br>
                            â€¢ Log all access attempts to Sentinel<br><br>
                            
                            <strong>Conditional Access for Privileged Operations</strong><br>
                            Layer additional controls on privileged access:<br>
                            â€¢ Require managed/compliant device<br>
                            â€¢ Block access from risky locations<br>
                            â€¢ Require phishing-resistant MFA (FIDO2, Windows Hello)<br><br>
                            
                            <strong>Monitoring</strong><br>
                            All PIM activations and Key Vault accesses flow to Sentinel. I've built detection rules for anomalous privileged access patterns."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- TECHNICAL DEEP DIVE - VULN MANAGEMENT -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-orange-500/20 flex items-center justify-center text-orange-400">15</span>
                    Technical Deep Dive: Vulnerability Management
                </h2>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-orange-400 font-bold mb-3">Q13: How do you prioritize vulnerability remediation when you have thousands of findings across your environment?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "At Siemens, we use Microsoft Defender Threat and Vulnerability Management (TVM), which helps with prioritization. But the framework I apply is tool-agnostic:<br><br>
                            
                            <strong>My Prioritization Framework</strong><br>
                            â€¢ <strong>Tier 1 - Immediate (24-48 hours)</strong>: Critical vulns on internet-facing systems OR any actively exploited vulnerability (KEV list). These get emergency patching.<br>
                            â€¢ <strong>Tier 2 - Urgent (7 days)</strong>: High-severity on internal systems with sensitive data, or critical on internal systems.<br>
                            â€¢ <strong>Tier 3 - Standard (30 days)</strong>: Medium severity or high severity with significant compensating controls already in place.<br>
                            â€¢ <strong>Tier 4 - Scheduled (next maintenance window)</strong>: Low severity, or vulnerabilities on isolated systems with limited exposure.<br><br>
                            
                            <strong>Key Factors Beyond CVSS</strong><br>
                            CVSS alone isn't enough. I consider:<br>
                            â€¢ <strong>Asset criticality</strong> - A medium vuln on a payment system matters more than a critical vuln on a test server<br>
                            â€¢ <strong>Exploit availability</strong> - Is there a public exploit? Is it actively used in the wild?<br>
                            â€¢ <strong>Network exposure</strong> - Internet-facing vs. internal vs. isolated<br>
                            â€¢ <strong>Compensating controls</strong> - Do we have EDR, segmentation, or other mitigations that reduce real risk?<br>
                            â€¢ <strong>Data classification</strong> - What's at stake if this system is compromised?<br><br>
                            
                            <strong>Practical Reality</strong><br>
                            You'll never get to zero vulnerabilities. The goal is reducing risk, not chasing metrics. I'd rather have 100 well-prioritized vulnerabilities being actively worked than 10,000 in a spreadsheet no one looks at."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-orange-400 font-bold mb-3">Q14: Describe your experience with vulnerability scanning in OT/ICS environments and how it differs from traditional IT scanning.</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I'll be upfrontâ€”I don't have hands-on OT vulnerability scanning experience. My background is IT security. However, I've studied the principles and understand why it's fundamentally different:<br><br>
                            
                            <strong>Why IT Scanning Doesn't Work in OT</strong><br>
                            â€¢ <strong>Fragility</strong> - Active scanning can crash PLCs or disrupt processes. I've read case studies where a Nessus scan brought down a manufacturing line. You can't just run authenticated scans against a 20-year-old controller.<br>
                            â€¢ <strong>Availability priority</strong> - In IT, we accept some downtime for security. In OT, unplanned downtime can cost millions or create safety risks.<br>
                            â€¢ <strong>Legacy systems</strong> - Many OT systems run Windows XP or proprietary RTOS that vendors won't update. Traditional patch management doesn't apply.<br>
                            â€¢ <strong>Vendor dependencies</strong> - Changes often require vendor approval or void support contracts.<br><br>
                            
                            <strong>What I'd Do Instead</strong><br>
                            â€¢ <strong>Passive monitoring</strong> - Tools like Claroty, Nozomi, or Dragos that analyze network traffic without sending packets. They can identify assets, vulnerabilities, and anomalies without active probing.<br>
                            â€¢ <strong>Scheduled maintenance windows</strong> - If active scanning is needed, coordinate with plant operations during planned downtime.<br>
                            â€¢ <strong>Virtual patching</strong> - When you can't patch, add compensating controlsâ€”network segmentation, IPS rules, enhanced monitoring.<br>
                            â€¢ <strong>Asset inventory first</strong> - You can't secure what you don't know exists. Build a detailed inventory of OT assets, firmware versions, and vendor support status.<br><br>
                            
                            <strong>How I'd Contribute</strong><br>
                            This is an area I want to learn. I'd work closely with your OT team to understand the constraints and bring my IT security engineering skills to help bridge the gap."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6">
                    <p class="text-orange-400 font-bold mb-3">Q15: Your vulnerability scanner is producing a high rate of false positives. How do you address this while maintaining effective vulnerability management?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "False positives erode trust in the vulnerability management program. If teams learn that most findings are noise, they start ignoring everything. Here's how I'd address it:<br><br>
                            
                            <strong>1. Root Cause Analysis</strong><br>
                            First, understand WHY we're getting false positives:<br>
                            â€¢ <strong>Authentication issues</strong> - Scanner can't authenticate and is making assumptions based on banners. Fix credentials or deploy authenticated scanning.<br>
                            â€¢ <strong>Version detection problems</strong> - Scanner thinks it's vulnerable based on version string, but we've backported the fix. Common with RHEL/CentOS.<br>
                            â€¢ <strong>Environment-specific issues</strong> - Scanner doesn't understand our configuration or compensating controls.<br><br>
                            
                            <strong>2. Tune Scanner Policies</strong><br>
                            â€¢ Disable checks that consistently produce false positives for our specific stack<br>
                            â€¢ Adjust scanning intensityâ€”sometimes aggressive scans trigger false positives<br>
                            â€¢ Create documented exceptions with justification for each<br><br>
                            
                            <strong>3. Validation Process</strong><br>
                            Before sending findings to remediation teams, security analysts should validate a sample. Build a knowledge base of common false positives. This also builds credibilityâ€”when you DO send a finding, teams know it's real.<br><br>
                            
                            <strong>4. Feedback Loop</strong><br>
                            When a team reports a false positive, investigate and update policies. Track false positive rates over time as a quality metric.<br><br>
                            
                            <strong>My Experience</strong><br>
                            With Defender TVM, I've seen similar issuesâ€”particularly with version detection on custom-built applications. The solution was working with dev teams to ensure accurate version reporting and creating exceptions where appropriate."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- TECHNICAL DEEP DIVE - DLP & EMAIL -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-pink-500/20 flex items-center justify-center text-pink-400">16</span>
                    Technical Deep Dive: DLP & Email Security
                </h2>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-pink-400 font-bold mb-3">Q16: How would you design and implement a DLP program that protects sensitive data without creating excessive friction for users?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "This is my wheelhouseâ€”I'm currently leading a Purview DLP migration from Symantec, and user friction was a major design consideration. Here's my approach:<br><br>
                            
                            <strong>1. Start with Data Classification</strong><br>
                            Before writing any DLP policy, understand what you're protecting. Work with business units to identify:<br>
                            â€¢ What data actually needs protection (not everything is sensitive)<br>
                            â€¢ Where it lives and how it flows<br>
                            â€¢ Who needs legitimate access<br>
                            This prevents over-broad policies that block everything.<br><br>
                            
                            <strong>2. Phased Enforcement: Simulation â†’ Audit â†’ Warn â†’ Block</strong><br>
                            This is critical. At Siemens, we run every new policy through this progression:<br>
                            â€¢ <strong>Simulation</strong> - Policy runs invisibly, just collecting data on what WOULD be blocked<br>
                            â€¢ <strong>Audit</strong> - Log violations but don't show users anything yet<br>
                            â€¢ <strong>Warn</strong> - Show users a policy tip, let them override with justification<br>
                            â€¢ <strong>Block</strong> - Only after we've validated the policy doesn't break legitimate workflows<br><br>
                            
                            <strong>3. Contextual Policies</strong><br>
                            In Purview, I use conditions beyond just 'contains SSN':<br>
                            â€¢ Recipient domain - Internal vs. external makes a difference<br>
                            â€¢ Sender department - Finance sharing financial data is different than random employee<br>
                            â€¢ File location - SharePoint to SharePoint is different than SharePoint to personal email<br>
                            â€¢ User override - Allow justified business exceptions with audit trail<br><br>
                            
                            <strong>4. Clear User Communication</strong><br>
                            Policy tips should explain WHY something was blocked and WHAT the user can do. 'Policy violation' means nothing. 'This email contains what appears to be credit card numbers. If this is legitimate business, click here to request an exception' is actionable.<br><br>
                            
                            <strong>Result</strong><br>
                            Our Purview migration achieved 40% reduction in false positives compared to Symantec through better contextual logic and SIT confidence tuning."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-pink-400 font-bold mb-3">Q17: Explain your approach to combating sophisticated phishing attacks that bypass traditional email security controls.</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "Phishing is the initial access vector for most breaches, so this is a constant focus. Here's my defense-in-depth approach:<br><br>
                            
                            <strong>Technical Controls (Email Layer)</strong><br>
                            â€¢ <strong>SPF/DKIM/DMARC</strong> - Properly configured to reject failures, not just quarantine. This blocks domain spoofing.<br>
                            â€¢ <strong>Microsoft Defender for Office 365</strong> - Safe Links rewrites URLs and checks at time-of-click, not just delivery. Safe Attachments detonates in sandbox.<br>
                            â€¢ <strong>Anti-spoofing policies</strong> - Protect against look-alike domains and display name impersonation<br>
                            â€¢ <strong>External email tagging</strong> - Banner on external emails so users know when something comes from outside<br><br>
                            
                            <strong>Technical Controls (Beyond Email)</strong><br>
                            â€¢ <strong>Conditional Access</strong> - Even if credentials are phished, attackers can't use them without a compliant device and MFA<br>
                            â€¢ <strong>Phishing-resistant MFA</strong> - FIDO2 keys or Windows Hello for Business can't be phished via AitM (Adversary in the Middle) attacks<br>
                            â€¢ <strong>Browser isolation</strong> - High-risk links open in isolated container<br>
                            â€¢ <strong>EDR/MDE</strong> - Catches credential harvesting attempts on endpoints<br><br>
                            
                            <strong>User Training</strong><br>
                            â€¢ Regular phishing simulations with immediate training for clickers<br>
                            â€¢ Make reporting easyâ€”one-click 'Report Phish' button in Outlook<br>
                            â€¢ Recognize and reward good catches<br>
                            â€¢ Focus on verification procedures, not just 'don't click suspicious links'<br><br>
                            
                            <strong>Detection & Response</strong><br>
                            â€¢ Sentinel detections for impossible travel, suspicious inbox rules, mail forwarding to external addresses<br>
                            â€¢ Regular review of risky sign-ins in Entra ID<br>
                            â€¢ Playbook for compromised account response (which I can detail if you ask)"
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6">
                    <p class="text-pink-400 font-bold mb-3">Q18: A business executive's account is compromised and sending phishing emails internally. Walk through your incident response process.</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "This is a critical scenarioâ€”executive accounts have high trust and access. Speed matters. Here's my response:<br><br>
                            
                            <strong>Immediate Containment (First 15 Minutes)</strong><br>
                            â€¢ <strong>Disable the account</strong> - Stop the bleeding. In Entra ID, disable sign-in, revoke all refresh tokens<br>
                            â€¢ <strong>Block/recall malicious emails</strong> - Use Defender for O365 Threat Explorer to find and delete the phishing emails from all mailboxes<br>
                            â€¢ <strong>Reset password</strong> - Even though account is disabled, reset password immediately<br>
                            â€¢ <strong>Notify the executive</strong> - Through out-of-band channel (phone call), not email<br><br>
                            
                            <strong>Impact Assessment (Next 1-2 Hours)</strong><br>
                            â€¢ <strong>Who received the phishing?</strong> - Get full recipient list from Threat Explorer<br>
                            â€¢ <strong>Who clicked?</strong> - Check Safe Links click data and EDR for any secondary compromises<br>
                            â€¢ <strong>What did attacker access?</strong> - Review Unified Audit Log for mailbox access, file downloads, SharePoint access<br>
                            â€¢ <strong>Persistence mechanisms?</strong> - Check for inbox rules forwarding to external addresses, OAuth app consents, delegates added<br><br>
                            
                            <strong>Investigation</strong><br>
                            â€¢ <strong>Initial access vector</strong> - Check sign-in logs. Where did the compromise happen? Phishing? Credential stuffing? AitM?<br>
                            â€¢ <strong>Timeline reconstruction</strong> - Build a timeline of attacker actions using Sentinel and UAL<br>
                            â€¢ <strong>Lateral movement</strong> - Did they access other systems? Check MDE for activity from compromised device<br><br>
                            
                            <strong>Communication & Recovery</strong><br>
                            â€¢ <strong>Org-wide alert</strong> - 'We detected a phishing campaign from [compromised user]. Do not click links in emails from them sent between [times]. If you clicked, contact IT Security immediately.'<br>
                            â€¢ <strong>Re-enable account</strong> - Only after removing all persistence, resetting credentials, validating MFA, and briefing the executive on what happened<br><br>
                            
                            <strong>Post-Incident</strong><br>
                            â€¢ Document lessons learned<br>
                            â€¢ Improve controls (Was MFA phishable? Do we need hardware keys for executives?)<br>
                            â€¢ Update detection rules based on what we learned"
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- TECHNICAL DEEP DIVE - EDR -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-red-500/20 flex items-center justify-center text-red-400">17</span>
                    Technical Deep Dive: Endpoint Detection & Response
                </h2>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-red-400 font-bold mb-3">Q19: How do you balance EDR sensitivity to detect advanced threats while minimizing alert fatigue for the security team?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "This is something I dealt with extensively during the ESET to MDE migration. Alert fatigue is realâ€”if analysts are drowning in noise, they miss the real threats. Here's my approach:<br><br>
                            
                            <strong>Start with Baselines</strong><br>
                            When we deployed MDE, I started with Microsoft's recommended policies but ran them in audit mode for two weeks. This showed me what normal looks like in our environmentâ€”which admin tools trigger alerts, what scheduled tasks run, which scripts are legitimate.<br><br>
                            
                            <strong>Tuning Strategy</strong><br>
                            â€¢ <strong>Allowlists for known-good</strong> - After validation, create exclusions for legitimate admin tools, LOB applications, and automated processes. Document WHY each exclusion exists.<br>
                            â€¢ <strong>Suppression rules</strong> - For repetitive low-value alerts that can't be excluded, create suppression rules. Example: Alert on PowerShell execution from specific service account that runs approved automation.<br>
                            â€¢ <strong>Severity adjustment</strong> - Not every 'High' alert is actually high in our context. Tune severity based on our environment.<br><br>
                            
                            <strong>Alert Triage Workflow</strong><br>
                            â€¢ <strong>Tier 1</strong> - High-confidence, high-severity alerts get immediate analyst attention<br>
                            â€¢ <strong>Tier 2</strong> - Medium-confidence alerts are batched for periodic review<br>
                            â€¢ <strong>Automated enrichment</strong> - Before an analyst sees an alert, it's automatically enriched with asset context, user info, threat intel. This saves investigation time.<br><br>
                            
                            <strong>Metrics I Track</strong><br>
                            â€¢ Alert volume by category (trending up or down?)<br>
                            â€¢ True positive rate (are we tuning effectively?)<br>
                            â€¢ Mean time to triage and resolve<br>
                            â€¢ Coverage gaps (any endpoint types not generating expected telemetry?)<br><br>
                            
                            The goal is high-fidelity alerts. I'd rather have 10 meaningful alerts per day than 1,000 that analysts ignore."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-red-400 font-bold mb-3">Q20: Describe a situation where you had to investigate a potential ransomware infection. What EDR capabilities would you leverage?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I haven't responded to an active ransomware incident, but I've investigated suspicious activity that could have been pre-ransomware. Here's my EDR-based investigation approach:<br><br>
                            
                            <strong>Immediate Actions</strong><br>
                            â€¢ <strong>Network isolation</strong> - In MDE, I can isolate the endpoint immediately while maintaining agent connectivity. This stops lateral movement while preserving my investigation ability.<br>
                            â€¢ <strong>Kill suspicious processes</strong> - If I see active encryption (rapid file modifications), kill the process immediately using MDE Live Response.<br><br>
                            
                            <strong>Investigation Using MDE</strong><br>
                            â€¢ <strong>Device timeline</strong> - Walk through the execution chain. What ran, when, from where? Look for suspicious process treesâ€”especially Word/Excel spawning PowerShell, or unknown executables from Temp folders.<br>
                            â€¢ <strong>File analysis</strong> - Check hash reputation. Is it known malware? When was it first seen globally vs. in our environment?<br>
                            â€¢ <strong>Network connections</strong> - Any C2 communication? Unusual outbound connections?<br>
                            â€¢ <strong>Persistence mechanisms</strong> - Registry modifications, scheduled tasks, services created<br><br>
                            
                            <strong>Scope Assessment</strong><br>
                            Once I understand the infection, I need to know if it spread:<br>
                            â€¢ Search for the same hash across all endpoints<br>
                            â€¢ Look for same C2 domains/IPs in network logs<br>
                            â€¢ Check for lateral movement indicatorsâ€”pass-the-hash, RDP from infected system<br><br>
                            
                            <strong>Evidence Collection</strong><br>
                            Using MDE Live Response:<br>
                            â€¢ Collect memory dump before remediation<br>
                            â€¢ Grab relevant event logs, prefetch, registry hives<br>
                            â€¢ Capture suspicious files for further analysis<br><br>
                            
                            <strong>Remediation</strong><br>
                            â€¢ Remove malware and persistence<br>
                            â€¢ Coordinate with backup team for data recovery if needed<br>
                            â€¢ Reset credentials for affected user<br>
                            â€¢ Root cause analysisâ€”how did it get in?"
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6">
                    <p class="text-red-400 font-bold mb-3">Q21: How would you deploy EDR to a large fleet of endpoints with minimal disruption to business operations?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I did exactly this at Siemensâ€”migrating from ESET to MDE across our endpoint fleet. Here's what I learned:<br><br>
                            
                            <strong>Planning Phase</strong><br>
                            â€¢ <strong>Pilot group selection</strong> - Start with IT department endpoints. They're technical, tolerant of issues, and give good feedback.<br>
                            â€¢ <strong>Coexistence testing</strong> - We ran MDE alongside ESET initially to validate there were no conflicts. Some EDR combinations fight each other.<br>
                            â€¢ <strong>Performance baseline</strong> - Measure system performance before deployment so you can compare.<br><br>
                            
                            <strong>Deployment Strategy</strong><br>
                            â€¢ <strong>Wave-based rollout</strong> - We did IT â†’ Engineering â†’ Finance â†’ Operations. Each wave was ~10% of fleet.<br>
                            â€¢ <strong>SCCM/Intune deployment</strong> - Used existing endpoint management for automated installation. No manual intervention needed.<br>
                            â€¢ <strong>Maintenance windows</strong> - For servers, scheduled during approved change windows.<br><br>
                            
                            <strong>Key Lesson: The Onboarding Script Issue</strong><br>
                            We discovered that cloning from golden images caused all VMs to share the same device ID in MDE. Telemetry collapsedâ€”multiple servers looked like one device. Solution: Enforce post-image onboarding script that generates unique device IDs. This is now part of our standard deployment process.<br><br>
                            
                            <strong>Monitoring During Rollout</strong><br>
                            â€¢ Built a deployment health dashboard showing agent status, version, last check-in<br>
                            â€¢ Monitored for performance complaints<br>
                            â€¢ Tracked policy application status<br><br>
                            
                            <strong>Post-Deployment Optimization</strong><br>
                            â€¢ Started with policies in audit mode<br>
                            â€¢ Tuned based on environment-specific noise<br>
                            â€¢ Gradually moved to enforcement<br>
                            â€¢ Documented exclusions and their justifications"
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- TECHNICAL DEEP DIVE - FRAMEWORKS -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-cyan-500/20 flex items-center justify-center text-cyan-400">18</span>
                    Technical Deep Dive: Security Frameworks & Compliance
                </h2>

                <div class="technical rounded-xl p-6 mb-4">
                    <p class="text-cyan-400 font-bold mb-3">Q22: How do you approach aligning security controls with multiple frameworks like NIST, ISO 27001, and SOC 2 simultaneously?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "The key insight is that frameworks overlap significantly. You're not implementing three separate programsâ€”you're implementing one security program that maps to multiple frameworks. Here's my approach:<br><br>
                            
                            <strong>Unified Control Framework</strong><br>
                            I create a master control set that satisfies all applicable frameworks. For example, MFA implementation satisfies:<br>
                            â€¢ NIST 800-53 IA-2 (Identification and Authentication)<br>
                            â€¢ ISO 27001 A.9.4.2 (Secure log-on procedures)<br>
                            â€¢ SOC 2 CC6.1 (Logical access controls)<br>
                            One implementation, three frameworks checked off.<br><br>
                            
                            <strong>Practical Example from My Work</strong><br>
                            Our Sentinel deployment maps to multiple framework requirements:<br>
                            â€¢ <strong>NIST DE.AE-1</strong> (Anomaly detection) â†’ Sentinel UEBA and analytics rules<br>
                            â€¢ <strong>ISO A.12.4.1</strong> (Event logging) â†’ Sentinel data connectors and retention<br>
                            â€¢ <strong>SOC 2 CC7.2</strong> (Security monitoring) â†’ Real-time alerting and dashboards<br><br>
                            
                            <strong>Evidence Management</strong><br>
                            â€¢ Collect evidence once, use for multiple audits<br>
                            â€¢ Screenshot of Sentinel analytics rule satisfies logging requirements for all three frameworks<br>
                            â€¢ Maintain clear documentation mapping controls to framework requirements<br><br>
                            
                            <strong>Gap Analysis Process</strong><br>
                            When assessing compliance:<br>
                            1. List all requirements from applicable frameworks<br>
                            2. Map existing controls to requirements<br>
                            3. Identify gaps where no control exists<br>
                            4. Prioritize remediation based on risk, not checkbox counting<br>
                            5. Track progress and evidence in a centralized system<br><br>
                            
                            The goal is security effectiveness, not audit theater. Good security naturally maps to frameworks."
                        </p>
                    </div>
                </div>

                <div class="technical rounded-xl p-6">
                    <p class="text-cyan-400 font-bold mb-3">Q23: Explain how you would use CIS Benchmarks to establish security baselines across a diverse infrastructure.</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "CIS Benchmarks are prescriptive and actionableâ€”exactly what you need for establishing baselines. Here's my implementation approach:<br><br>
                            
                            <strong>Benchmark Selection</strong><br>
                            â€¢ Identify all platforms in the environment (Windows Server, Windows 10/11, Ubuntu, Azure, etc.)<br>
                            â€¢ Download the applicable CIS Benchmarks<br>
                            â€¢ Choose profile level: Level 1 for most systems (balanced security/operability), Level 2 for high-security systems<br><br>
                            
                            <strong>Customization</strong><br>
                            CIS Benchmarks are recommendations, not mandates. Some don't fit every environment:<br>
                            â€¢ Review each control against business and technical requirements<br>
                            â€¢ Document exceptions with business justification<br>
                            â€¢ Get stakeholder approval before finalizing baseline<br><br>
                            
                            <strong>Implementation Methods</strong><br>
                            â€¢ <strong>Golden images</strong> - Bake CIS hardening into base images for VMs. Every new system starts compliant.<br>
                            â€¢ <strong>Group Policy</strong> - For Windows environments, import CIS GPO templates<br>
                            â€¢ <strong>Azure Policy</strong> - Use built-in CIS benchmark initiatives for Azure resources<br>
                            â€¢ <strong>Configuration management</strong> - Ansible playbooks or DSC for ongoing enforcement and drift remediation<br><br>
                            
                            <strong>Compliance Scanning</strong><br>
                            â€¢ Use Defender for Cloud for continuous CIS assessment in Azure<br>
                            â€¢ On-prem, tools like CIS-CAT or Qualys can assess against benchmarks<br>
                            â€¢ Build dashboards showing compliance percentage by system type<br><br>
                            
                            <strong>Continuous Process</strong><br>
                            â€¢ Schedule regular scans (weekly or monthly)<br>
                            â€¢ Alert on critical deviations<br>
                            â€¢ Update baselines when CIS releases new benchmark versions<br>
                            â€¢ Review exceptions annuallyâ€”are they still valid?"
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- JOB REQUIREMENT DEEP DIVE QUESTIONS -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-orange-500/20 flex items-center justify-center text-orange-400">19</span>
                    Job Requirement Deep Dive Questions
                </h2>

                <p class="text-gray-400 text-sm mb-6">These questions are mapped directly to the job posting requirements. Each answer demonstrates relevant experience while being honest about areas where you're still growing.</p>

                <!-- PAM Section -->
                <div class="technical rounded-xl p-6 mb-6">
                    <p class="text-emerald-400 font-bold mb-4">Q: Tell me about your experience with Privileged Access Management (PAM).</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I want to be transparentâ€”I haven't directly administered a PAM solution like CyberArk or BeyondTrust. I haven't been the one creating vaults, onboarding accounts, or configuring session recording policies. However, I've worked extensively with PAM from the <strong class="text-emerald-400">SIEM integration and detection engineering side</strong>, which has given me a solid understanding of how these systems work and what good PAM security looks like.
                            <br><br>
                            <strong class="text-emerald-400">What I've actually done:</strong>
                            <br><br>
                            <strong>Log Integration:</strong> I've integrated PAM logs into our SIEMâ€”configuring the log forwarding, parsing the events, and ensuring we have visibility into privileged access activities. This means I understand the data PAM systems generate: session initiation, credential checkouts, password rotations, failed authentications, policy violations.
                            <br><br>
                            <strong>Detection Rules:</strong> I've built detection rules around PAM eventsâ€”alerting on privileged sessions outside business hours, sessions to systems the user doesn't normally access, multiple failed vault authentications that might indicate credential attacks, and credential checkouts without corresponding sessions (potential credential theft).
                            <br><br>
                            <strong>Incident Investigation:</strong> When we investigate security incidents involving privileged access, I pull PAM session recordings and logs as part of forensics. This has taught me what PAM captures and how to use it for incident response.
                            <br><br>
                            <strong class="text-emerald-400">My understanding of PAM architecture:</strong>
                            <br><br>
                            I understand the core componentsâ€”the vault that stores credentials, the session manager that brokers and records connections, the password rotation component that automatically changes credentials, and the access portal where users request and receive just-in-time access.
                            <br><br>
                            I understand <strong>why PAM matters</strong>: privileged credentials are the keys to the kingdom. If an attacker gets domain admin credentials, game over. PAM addresses this by eliminating standing privileges (just-in-time access), removing credential knowledge from users (they never see the actual password), providing accountability through session recording, and reducing attack surface through automatic rotation.
                            <br><br>
                            <strong class="text-emerald-400">Key PAM concepts I'm familiar with:</strong>
                            <br><br>
                            â€¢ <strong>Just-in-Time (JIT) Access</strong> â€” Privileges granted only when needed, automatically revoked after
                            <br>â€¢ <strong>Credential Vaulting</strong> â€” Secrets stored encrypted, never exposed to end users
                            <br>â€¢ <strong>Session Isolation</strong> â€” Users connect through jump hosts, never directly to targets
                            <br>â€¢ <strong>Session Recording</strong> â€” Full video and keystroke capture for forensics and compliance
                            <br>â€¢ <strong>Automatic Rotation</strong> â€” Credentials changed regularly without human intervention
                            <br>â€¢ <strong>Break-glass Procedures</strong> â€” Emergency access with enhanced logging and alerts
                            <br><br>
                            <strong class="text-emerald-400">What I'd bring:</strong>
                            <br><br>
                            I understand PAM from the security monitoring perspectiveâ€”I know what good looks like, what to alert on, and how PAM fits into the broader security architecture. If this role involves hands-on PAM administration, I'd need to ramp up on the specific platform, but the conceptual foundation is solid. I'm genuinely interested in expanding into this area because PAM is critical for any mature security program."
                        </p>
                    </div>
                </div>

                <!-- CASB Section -->
                <div class="technical rounded-xl p-6 mb-6">
                    <p class="text-emerald-400 font-bold mb-4">Q: What's your experience with CASB solutions and securing SaaS applications?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "Similar to PAM, I haven't directly administered a CASB solutionâ€”I haven't been the one configuring app connectors, building session policies, or managing the shadow IT discovery dashboards. But I've worked with CASB from the <strong class="text-emerald-400">SIEM integration and detection side</strong>, which has given me a strong understanding of what CASB does and how it fits into cloud security.
                            <br><br>
                            <strong class="text-emerald-400">What I've actually done:</strong>
                            <br><br>
                            <strong>Log Integration:</strong> I've ingested CASB alerts and telemetry into Sentinelâ€”Microsoft Defender for Cloud Apps in our case. This includes shadow IT discovery data, app usage patterns, policy violations, and anomalous behavior alerts. I understand the data model and what events CASB generates.
                            <br><br>
                            <strong>Detection Rules:</strong> I've correlated CASB events with other security dataâ€”for example, combining Defender for Cloud Apps alerts about risky file sharing with DLP events to get a fuller picture of potential data exfiltration. When a user uploads sensitive files to an unsanctioned cloud app, we want to see that alongside what else that user was doing.
                            <br><br>
                            <strong>Alert Triage:</strong> I've investigated CASB alerts as part of SOC operationsâ€”unusual app usage, impossible travel scenarios, mass downloads. This taught me what CASB detects and how to validate whether it's a true positive.
                            <br><br>
                            <strong class="text-emerald-400">My understanding of CASB capabilities:</strong>
                            <br><br>
                            I understand CASB as the visibility and control layer for SaaS applications that you otherwise can't see at the network level. Everything's HTTPS now, so traditional firewalls just see encrypted traffic to cloud IPs. CASB solves this through:
                            <br><br>
                            â€¢ <strong>Shadow IT Discovery</strong> â€” Identifying which cloud apps users are actually using, risk-scoring them, enabling informed sanctioning decisions
                            <br><br>
                            â€¢ <strong>API Connectors</strong> â€” Deep integration with sanctioned SaaS apps (M365, Salesforce, Box) to see inside the applicationâ€”file sharing, permissions, admin activitiesâ€”not just 'traffic went to that domain'
                            <br><br>
                            â€¢ <strong>Inline/Proxy Controls</strong> â€” Real-time policy enforcement through Conditional Access App Control. Allow access from unmanaged devices but block downloads. Require step-up authentication for sensitive operations.
                            <br><br>
                            â€¢ <strong>DLP Integration</strong> â€” Detecting sensitive content being uploaded to cloud storage, blocking or alerting based on policy
                            <br><br>
                            â€¢ <strong>Threat Detection</strong> â€” Anomalous behavior, compromised accounts, malware in cloud storage
                            <br><br>
                            <strong class="text-emerald-400">Why CASB matters in Zero Trust:</strong>
                            <br><br>
                            In a Zero Trust model, you're not just asking 'did traffic go to Dropbox?'â€”you're asking 'who is this user, what device are they on, what are they trying to do with what data, and does that make sense given their role?' CASB gives you the visibility to answer those questions for cloud applications, which is critical when your data lives in SaaS platforms you don't control.
                            <br><br>
                            <strong class="text-emerald-400">What I'd bring:</strong>
                            <br><br>
                            I understand CASB architecturally and from the detection/monitoring perspective. If this role requires hands-on CASB administration, I'd need to learn the specific console and policy configuration, but I understand what good CASB implementation looks like and how to measure its effectiveness. I'm eager to expand into this areaâ€”cloud security is clearly where the industry is heading."
                        </p>
                    </div>
                </div>

                <!-- Key Management Section -->
                <div class="technical rounded-xl p-6 mb-6">
                    <p class="text-emerald-400 font-bold mb-4">Q: How do you approach key management and secrets management in enterprise environments?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I'll be honestâ€”I haven't directly administered a key management solution like Azure Key Vault or HashiCorp Vault. I haven't been the one creating vaults, configuring access policies, or setting up certificate rotation. However, I have <strong class="text-emerald-400">comprehensive knowledge of how key management works</strong> and why it's critical, gained through studying for certifications, working adjacent to these systems, and understanding their role in the security architecture.
                            <br><br>
                            <strong class="text-emerald-400">Where my experience connects:</strong>
                            <br><br>
                            <strong>Security Monitoring:</strong> I've seen what happens when key management goes wrongâ€”alerts triggered by secrets accidentally committed to source control, API keys exposed in logs, certificates expiring unexpectedly. From the SIEM side, I understand the events these systems generate and what anomalies to watch for.
                            <br><br>
                            <strong>Automation Work:</strong> When writing scripts and automation, I've followed the principle of never hardcoding credentials. Even in my personal projects, I use environment variables and secrets management rather than embedding API keys in code. I understand <em>why</em> this matters even if I haven't administered enterprise-scale key vaults.
                            <br><br>
                            <strong class="text-emerald-400">My understanding of key management principles:</strong>
                            <br><br>
                            <strong>Secrets Should Never Be in Code:</strong> Not in source control, not in config files, not hardcoded anywhere. Secrets belong in a vault, injected at runtime, rotated regularly. Tools like git-secrets and truffleHog exist specifically because this is such a common mistake.
                            <br><br>
                            <strong>Least Privilege Access:</strong> Applications should only access the specific secrets they need. A web app shouldn't have access to database admin credentials just because they're in the same vault.
                            <br><br>
                            <strong>Rotation Without Downtime:</strong> Good architecture supports credential rotation without breaking applications. This means applications retrieve secrets dynamically rather than caching them indefinitely.
                            <br><br>
                            <strong>Audit Everything:</strong> Every secret access should be logged. If a credential is compromised, you need to know what accessed it and when.
                            <br><br>
                            <strong class="text-emerald-400">Key concepts I understand:</strong>
                            <br><br>
                            â€¢ <strong>Azure Key Vault</strong> â€” Secrets, keys, and certificates stored centrally. Managed identities for Azure resources to authenticate without storing credentials. RBAC for access control.
                            <br><br>
                            â€¢ <strong>HashiCorp Vault</strong> â€” Dynamic secrets generation, encryption as a service, multiple auth methods, popular in hybrid/multi-cloud environments.
                            <br><br>
                            â€¢ <strong>HSMs</strong> â€” Hardware Security Modules for highest-security key storage, FIPS 140-2 compliance, used for signing keys and keys protecting highly sensitive data.
                            <br><br>
                            â€¢ <strong>Certificate Lifecycle</strong> â€” Issuance, renewal, revocation. Auto-rotation to prevent expiration surprises. Certificate pinning considerations for applications.
                            <br><br>
                            <strong class="text-emerald-400">What I'd bring:</strong>
                            <br><br>
                            I understand key management conceptually and why it's foundational to secure architecture. I know what good looks like and what problems poor key management causes. If this role involves hands-on vault administration, I'd need to learn the specific platform, but I'd pick it up quickly because the principles are clear to me. This is an area I'm actively interested in growing intoâ€”secrets management is critical and often underinvested."
                        </p>
                    </div>
                </div>

                <!-- DevSecOps / CI-CD Section -->
                <div class="technical rounded-xl p-6 mb-6">
                    <p class="text-emerald-400 font-bold mb-4">Q: How would you approach securing a CI/CD pipeline? What are the key risks?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I want to be upfrontâ€”I haven't directly managed CI/CD pipelines in a production enterprise environment. My work experience has been more on the security operations side, where I've integrated log sources from custom applications and DevOps tools into our SIEM, giving me visibility into what happens in those environments. But my <strong class="text-emerald-400">hands-on CI/CD security experience comes from my personal projects</strong>, specifically my email security platform.
                            <br><br>
                            <strong class="text-emerald-400">What I built for my personal project:</strong>
                            <br><br>
                            For my email security platform, I designed the entire CI/CD workflow using <strong>GitHub Actions</strong>. I wanted to practice DevSecOps principles properly, so I implemented security scanning at multiple stages:
                            <br><br>
                            <strong>Pre-build scanning:</strong>
                            <br>â€¢ Secret scanning to catch any accidentally committed credentials before they hit the repo
                            <br>â€¢ Dependency scanning using free tools from the GitHub Actions marketplace to identify vulnerable packages
                            <br><br>
                            <strong>Build-level scanning:</strong>
                            <br>â€¢ SAST (Static Application Security Testing) to analyze my Python code for security issues
                            <br>â€¢ DAST (Dynamic Application Security Testing) against the running application
                            <br>â€¢ IaC scanning for any infrastructure configuration files
                            <br><br>
                            I used open-source scanners available in the GitHub marketplaceâ€”tools like Trivy for container scanning, Bandit for Python security linting, and others. The workflow fails the build if critical vulnerabilities are found, so I can't accidentally deploy insecure code.
                            <br><br>
                            I maintain this entire workflow myselfâ€”updating scanner versions, tuning rules to reduce false positives, and adding new checks as I learn about different vulnerability types. It's been a great learning experience because when something breaks or a scan flags an issue, I have to actually understand why and fix it.
                            <br><br>
                            <strong class="text-emerald-400">The key risks I understand:</strong>
                            <br><br>
                            <strong>1. Secrets Exposure</strong> â€” Pipelines need credentials to deploy, and if they're stored insecurelyâ€”plain text in configs, environment variables that get loggedâ€”attackers can steal them. In my project, I use GitHub Secrets and make sure nothing sensitive is echoed to logs.
                            <br><br>
                            <strong>2. Dependency Risks</strong> â€” Supply chain attacks like what happened with SolarWinds and Codecov show how compromised dependencies can inject malicious code into every deployment. That's why I pin dependency versions and scan for known vulnerabilities.
                            <br><br>
                            <strong>3. Pipeline-as-Code Vulnerabilities</strong> â€” If someone can modify the pipeline definition, they can inject malicious steps. Pipeline configs should get the same PR review scrutiny as application code.
                            <br><br>
                            <strong>4. Build Environment Security</strong> â€” Build agents often have broad permissions. Ephemeral environments that spin up fresh for each job and tear down after are more secure than persistent build servers.
                            <br><br>
                            <strong class="text-emerald-400">From my work experience:</strong>
                            <br><br>
                            While I haven't owned CI/CD security at work, I've been on the receiving endâ€”integrating application logs and DevOps telemetry into Sentinel, building detection rules for anomalies in deployment patterns, and helping remediate when scans identified issues in the codebase. I understand how CI/CD fits into the broader security ecosystem.
                            <br><br>
                            <strong class="text-emerald-400">What I'd bring:</strong>
                            <br><br>
                            I have the foundational knowledge and hands-on experience from my personal project. I understand the concepts, the tools, and the risks. If this role involves CI/CD security, I'd ramp up quickly because I've already done it at a smaller scaleâ€”scaling up to enterprise would be about learning the specific tools and processes, not learning the principles from scratch."
                        </p>
                    </div>
                </div>

                <!-- Network Security Section -->
                <div class="technical rounded-xl p-6 mb-6">
                    <p class="text-emerald-400 font-bold mb-4">Q: Walk me through your understanding of network security fundamentalsâ€”TCP/IP, VPNs, IPS. How do you apply this knowledge?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "Network security is foundational to everything else in security. While I haven't been a network engineer or firewall administratorâ€”I'm not the one configuring VPN tunnels or writing firewall rules dailyâ€”I have <strong class="text-emerald-400">strong foundational knowledge</strong> and apply it constantly in my security engineering work, particularly around SIEM integration, detection engineering, and troubleshooting.
                            <br><br>
                            <strong class="text-emerald-400">How I apply network knowledge:</strong>
                            <br><br>
                            <strong>Log Integration & Analysis:</strong> I've integrated firewall logs, VPN logs, and IPS alerts into our SIEM. This requires understanding what these systems log, what the fields mean, and what's normal versus anomalous. When I'm parsing Palo Alto traffic logs or FortiGate events, I need to understand source/destination IPs, ports, protocols, and actions to make sense of the data.
                            <br><br>
                            <strong>Detection Rules:</strong> I've built detection rules based on network telemetryâ€”alerting on unusual outbound connections, detecting potential C2 traffic patterns, identifying port scanning or reconnaissance activity, flagging connections to known malicious IPs. This requires understanding how attacks manifest at the network layer.
                            <br><br>
                            <strong>Incident Investigation:</strong> When investigating alerts, network fundamentals help me understand the attack chain. If I see a process making outbound connections on unusual ports, I need to assess whether that's legitimate or potential exfiltration. Understanding TCP handshakes helps me interpret connection states in logs.
                            <br><br>
                            <strong class="text-emerald-400">My understanding of core concepts:</strong>
                            <br><br>
                            <strong>TCP/IP & OSI Model:</strong>
                            <br>â€¢ I understand the layer modelâ€”how decisions are made at Layer 3/4 (IPs and ports) versus Layer 7 (application content)
                            <br>â€¢ TCP three-way handshakeâ€”when I see SYN floods in IDS alerts, I understand what's happening (connection state exhaustion)
                            <br>â€¢ DNSâ€”critical for both attacks (C2 over DNS, DNS tunneling, malicious domains) and defense. I've written detection rules for high-entropy DNS queries and unusual TXT record lookups
                            <br><br>
                            <strong>Firewalls & NGFWs:</strong>
                            <br>â€¢ I understand the difference between traditional firewalls (Layer 3/4, port-based) and NGFWs (Layer 7, application-aware, integrated IPS/URL filtering)
                            <br>â€¢ Concepts like App-ID, User-ID, SSL decryption, and why they matter for visibility
                            <br>â€¢ Rule ordering, implicit denies, and why 'any-any' rules are dangerous
                            <br><br>
                            <strong>VPNs:</strong>
                            <br>â€¢ IPsec conceptsâ€”IKE phases, security associations, why tunnel establishment can fail
                            <br>â€¢ Remote access VPN versus site-to-site
                            <br>â€¢ Split tunneling implications for securityâ€”some traffic bypasses corporate controls
                            <br><br>
                            <strong>IPS/IDS:</strong>
                            <br>â€¢ Signature-based detection versus behavioral/anomaly detection
                            <br>â€¢ False positive tuningâ€”you can't block on everything or you'll break applications
                            <br>â€¢ Network-based versus host-based detection
                            <br><br>
                            <strong class="text-emerald-400">Real application in my work:</strong>
                            <br><br>
                            When I'm troubleshooting why an endpoint isn't reporting to the MDE console, I think through the network pathâ€”is there a firewall blocking outbound HTTPS to Microsoft's endpoints? When I see a detection rule firing on unusual traffic, I can assess whether the source/destination/port combination makes sense. When correlating events across systems, I use network context to tie together what happened.
                            <br><br>
                            <strong class="text-emerald-400">What I'd bring:</strong>
                            <br><br>
                            I have the conceptual foundation that makes me effective at security monitoring and detection, even if I'm not configuring the network devices directly. If this role involves hands-on network device administration, I'd need to develop those skills, but the underlying knowledge is solid. I'm comfortable learning specific platformsâ€”the principles transfer."
                        </p>
                    </div>
                </div>

                <!-- Security Frameworks Section -->
                <div class="technical rounded-xl p-6 mb-6">
                    <p class="text-emerald-400 font-bold mb-4">Q: How do you work with security frameworks like NIST, ISO 27001, and SOC 2? How do you bridge the gap between compliance requirements and technical implementation?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "This is actually something I'm passionate aboutâ€”I'm even building a personal tool to help bridge the gap between GRC teams and security engineers because I've seen how often they talk past each other.
                            <br><br>
                            <strong class="text-emerald-400">My perspective on frameworks:</strong>
                            <br><br>
                            Frameworks give you a structured way to think about security comprehensively. The risk is treating them as checkbox exercises. The value is using them as a lens to identify gaps you might not have considered.
                            <br><br>
                            <strong class="text-emerald-400">NIST Cybersecurity Framework:</strong>
                            <br><br>
                            I use the five functionsâ€”Identify, Protect, Detect, Respond, Recoverâ€”as a mental model. When I'm evaluating our security posture, I ask: Do we know what we're protecting (Identify)? Do we have preventive controls (Protect)? Can we detect when something goes wrong (Detect)? Do we have response procedures (Respond)? Can we recover from incidents (Recover)?
                            <br><br>
                            For example, during our SIEM migration, I mapped our Sentinel detection rules to NIST categories. This helped us identify where we had strong detection coverage and where we had gaps. We had great coverage on endpoint threats but weaker coverage on data exfiltration detectionâ€”that informed our priorities.
                            <br><br>
                            <strong class="text-emerald-400">ISO 27001:</strong>
                            <br><br>
                            I've worked on control implementations that support ISO 27001 requirements, though I haven't led an ISO audit directly. The framework's emphasis on risk assessment and treatment is valuableâ€”not every control applies to every organization, and you need to justify your decisions based on your risk profile.
                            <br><br>
                            <strong class="text-emerald-400">SOC 2:</strong>
                            <br><br>
                            I understand SOC 2's trust service criteriaâ€”Security, Availability, Processing Integrity, Confidentiality, Privacy. When we implement controls, I think about how we'd demonstrate compliance to an auditor. Can we show evidence that this control is operating effectively? Do we have logs? Do we have documentation?
                            <br><br>
                            <strong class="text-emerald-400">Bridging GRC and Technical:</strong>
                            <br><br>
                            The challenge I've seen is translation. A GRC analyst reads a control that says 'implement access controls to protect sensitive data.' A security engineer needs to know: which data stores, what access mechanism, what's 'sensitive', who are authorized users?
                            <br><br>
                            I try to bridge this by:
                            <br><br>
                            â€¢ <strong>Mapping controls to technical implementations</strong> â€” 'This DLP policy satisfies control X.Y.Z' with specific configuration documented
                            <br>â€¢ <strong>Providing evidence proactively</strong> â€” When I implement something, I document how it addresses compliance requirements, including screenshots and config exports that auditors will eventually need
                            <br>â€¢ <strong>Speaking both languages</strong> â€” I can explain to GRC what a technical control does in compliance terms, and I can translate compliance requirements into specific technical tasks
                            <br><br>
                            That's actually why I'm building the GRC-Security bridge tool in my personal timeâ€”I want to systematize this translation so it's not dependent on individuals who happen to understand both worlds."
                        </p>
                    </div>
                </div>

                <!-- Scripting/Automation Section -->
                <div class="technical rounded-xl p-6 mb-6">
                    <p class="text-emerald-400 font-bold mb-4">Q: Tell me about your experience with Python and PowerShell for security automation. Can you give specific examples?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "Automation is essential for security at scaleâ€”you can't manually review every alert or manually configure every system. I use both PowerShell and Python, depending on the use case. But more importantly, I take initiative to identify manual, repetitive work and automate it. Let me give you two real examples.
                            <br><br>
                            <strong class="text-emerald-400">Example 1: FireEye HX Compliance Reporting Automation</strong>
                            <br><br>
                            At Infosys, we had <strong>14 FireEye HX consoles</strong> across the environment, and we needed to track endpoint complianceâ€”which devices had the agent installed and reporting versus which were missing coverage.
                            <br><br>
                            The manual process was painful: log into each HX console individually, download the device list, copy-paste the columns and rows into a master spreadsheet, then do a VLOOKUP against the endpoint and server inventory from the infrastructure team to identify non-reporting devices. We didn't have CMDB integration with the EDR, so this reconciliation was completely manual. It took hours every week, and it was error-proneâ€”easy to miss a console or mess up the VLOOKUP.
                            <br><br>
                            I automated the entire workflow. I wrote a Python script that:
                            <br><br>
                            â€¢ Connected to all 14 HX consoles via API and pulled the device inventory from each
                            <br>â€¢ Merged all the data into a single consolidated Excel file
                            <br>â€¢ Automatically performed the VLOOKUP against the infrastructure team's asset list
                            <br>â€¢ Generated a report showing compliant devices, non-reporting devices, and new devices not in the inventory
                            <br><br>
                            What used to take hours of manual work now ran in minutes with a single script execution. The best part? That automation is <strong>still in use today</strong>â€”even after I left, the team continued using it because it just works. That's the kind of lasting impact I try to have.
                            <br><br>
                            <strong class="text-emerald-400">Example 2: UEBA Resigned Employee Upload Automation</strong>
                            <br><br>
                            We had a weekly insider threat process where HR would send us a list of resigned employees, and we needed to upload them to our third-party UEBA platform so the system could prioritize monitoring those users for data exfiltration or other insider risks before their last day.
                            <br><br>
                            The manual process was convoluted: receive the email from HR with an attachment, RDP into a DMZ jump server, copy the file to a specific share path, then from the DMZ server SSH into the UEBA server, and manually upload the file. Multiple hops, multiple manual steps, easy to make mistakesâ€”wrong file format, missed a week, typos in the data.
                            <br><br>
                            Now, I couldn't fully automate this because the RDP GUI step in the middle can't be scripted easily. But I broke the problem into pieces and automated what I could:
                            <br><br>
                            <strong>Script 1 (runs on my workstation):</strong> Automatically downloads the attachment from HR's email, performs data cleaning and validation (correct columns, proper formatting, no duplicates), and places the cleaned file in the DMZ share folder. This eliminated manual data handling errors.
                            <br><br>
                            <strong>Script 2 (runs on the DMZ server after manual RDP login):</strong> Picks up the file from the share path, connects to the UEBA server via SSH, and uploads the file with proper error handling and confirmation.
                            <br><br>
                            So instead of 15-20 minutes of manual work with multiple opportunities for human error, it became: run Script 1, RDP to DMZ, run Script 2, done. Maybe 3 minutes total, and the data is validated automatically. Reduced errors significantly and made the process consistent regardless of who ran it.
                            <br><br>
                            <strong class="text-emerald-400">Other Automation Work:</strong>
                            <br><br>
                            <strong>MDE Onboarding:</strong> PowerShell scripts to automate Defender for Endpoint deploymentâ€”checking onboarding status, running the package, verifying registration, logging results. Critical for onboarding hundreds of servers.
                            <br><br>
                            <strong>ESET Removal:</strong> Scripted the password-protected uninstallation process, pulling credentials securely and verifying complete removal.
                            <br><br>
                            <strong>Personal Tools:</strong> My email security platform and malware investigation toolkit are Python-basedâ€”API integrations with VirusTotal, header parsing, IOC enrichment.
                            <br><br>
                            <strong>Logic Apps & XSOAR:</strong> Built Sentinel automation for alert enrichment, ServiceNow ticket creation, and notification workflows. Developed XSOAR playbooks for automated triage.
                            <br><br>
                            <strong class="text-emerald-400">My automation philosophy:</strong>
                            <br><br>
                            â€¢ <strong>Identify the pain</strong> â€” If I see people doing repetitive manual work, I ask 'can this be automated?'
                            <br>â€¢ <strong>Automate what you can</strong> â€” Even partial automation (like the UEBA example) reduces errors and saves time
                            <br>â€¢ <strong>Error handling matters</strong> â€” Scripts that fail silently are dangerous; I build in logging, validation, and alerting
                            <br>â€¢ <strong>Make it sustainable</strong> â€” Document it, comment the code, so the next person can maintain it
                            <br>â€¢ <strong>Build for the team</strong> â€” The FireEye script outlived my tenure because I built it to be used by anyone, not just me
                            <br><br>
                            I'm not a software developer, but I'm comfortable scripting to solve real problems. When I see inefficiency, my instinct is to fix itâ€”and automation is usually how."
                        </p>
                    </div>
                </div>

                <!-- Problem Solving Section -->
                <div class="technical rounded-xl p-6 mb-6">
                    <p class="text-emerald-400 font-bold mb-4">Q: Describe a complex technical problem you solved. Walk me through your approach.</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "Let me tell you about the MDE telemetry issue we discovered during our endpoint rolloutâ€”it was one of those problems where the symptoms were subtle but the impact was significant.
                            <br><br>
                            <strong class="text-emerald-400">The Problem:</strong>
                            <br><br>
                            After onboarding several hundred servers to Microsoft Defender for Endpoint, something felt off. When I ran queries in Sentinel against the DeviceProcessEvents table, I was seeing less data than expected. Some servers that I knew were active weren't appearing in queries. But they showed as 'healthy' in the MDE portal, so at first glance, nothing was wrong.
                            <br><br>
                            <strong class="text-emerald-400">Discovery Process:</strong>
                            <br><br>
                            I started by picking specific servers I knew well and querying their events. I noticed that events from what should be different servers had the same DeviceId. That was the red flagâ€”each device should have a unique identifier.
                            <br><br>
                            I dug deeper and found that multiple serversâ€”sometimes 5 or 10â€”were reporting under a single DeviceId. Their events were essentially colliding, making it impossible to investigate incidents properly. If Server A and Server B share a DeviceId, and I see a suspicious process, which server is actually affected?
                            <br><br>
                            <strong class="text-emerald-400">Root Cause Analysis:</strong>
                            <br><br>
                            I worked with the infrastructure team to understand how servers were provisioned. They were using golden imagesâ€”a base image with all standard software, including the MDE agent, cloned to create new servers.
                            <br><br>
                            The problem: when you clone a machine with MDE already onboarded, the clone inherits the DeviceId from the parent image. Microsoft expects you to run the onboarding script on each individual machine, which generates a unique DeviceId. Skipping this stepâ€”which seemed logical to the infra team because the agent was already installedâ€”broke the identity model.
                            <br><br>
                            <strong class="text-emerald-400">Solution:</strong>
                            <br><br>
                            For existing servers, we had to re-onboard them properly. I wrote a script that would offboard the machine (clearing the existing identity), wait for the change to sync, then re-onboard with a fresh identity.
                            <br><br>
                            For new deployments, I worked with infrastructure to update the provisioning process. The golden image would include the MDE agent but NOT be onboarded. A post-deployment script would run the onboarding process, ensuring each new server got its own DeviceId.
                            <br><br>
                            <strong class="text-emerald-400">Validation:</strong>
                            <br><br>
                            After remediation, I built a Sentinel workbook that monitored for DeviceId collisionsâ€”basically, are we seeing different hostnames reporting under the same DeviceId? This became part of our ongoing health monitoring.
                            <br><br>
                            <strong class="text-emerald-400">Lessons Learned:</strong>
                            <br><br>
                            â€¢ <strong>Trust but verify</strong> â€” 'Agent installed' doesn't mean 'working correctly.' I now have validation steps that check for proper functionality, not just presence.
                            <br>â€¢ <strong>Understand the deployment model</strong> â€” Security tools often have assumptions about how they'll be deployed. When those assumptions don't match reality, you get subtle bugs.
                            <br>â€¢ <strong>Instrument for ongoing detection</strong> â€” Finding this problem manually was painful. Building automated detection means we'll catch it faster if it happens again.
                            <br>â€¢ <strong>Collaborate early</strong> â€” If I'd been involved in the provisioning process earlier, we could have prevented this. Now I try to engage with infrastructure planning before deployments."
                        </p>
                    </div>
                </div>

                <!-- Cloud Security Deeper Dive -->
                <div class="technical rounded-xl p-6 mb-6">
                    <p class="text-emerald-400 font-bold mb-4">Q: How do you approach security differently in cloud environments versus on-premises? What are the unique challenges?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "Having worked through a hybrid migrationâ€”moving from on-prem Windows servers and RSA NetWitness to Azure and Microsoft Sentinelâ€”I've experienced this transition firsthand.
                            <br><br>
                            <strong class="text-emerald-400">The Fundamental Shift â€” Shared Responsibility:</strong>
                            <br><br>
                            On-prem, you own everythingâ€”physical security, network, hypervisor, OS, application. In cloud, it's shared. For IaaS, you're still responsible for OS and up. For PaaS, the provider handles more. For SaaS, you're mainly managing configuration and access.
                            <br><br>
                            This changes where you focus your security effort. I don't worry about physical data center security in Azureâ€”Microsoft handles that. But I absolutely worry about IAM configuration, because a misconfigured role assignment can expose everything.
                            <br><br>
                            <strong class="text-emerald-400">Identity Becomes the Perimeter:</strong>
                            <br><br>
                            On-prem, network segmentation was primary. Firewall rules, VLANs, physical separation. In cloud, identity is the primary control plane. Everything is API-driven, and access is controlled by Azure AD roles, managed identities, and Conditional Access policies.
                            <br><br>
                            This is why I've invested in understanding Azure AD deeplyâ€”Conditional Access, PIM, access reviews. A compromised identity in cloud can do far more damage than a compromised workstation on a segmented on-prem network.
                            <br><br>
                            <strong class="text-emerald-400">Configuration as Code, Misconfiguration as Risk:</strong>
                            <br><br>
                            Cloud resources are often deployed through templatesâ€”ARM, Terraform, CloudFormation. This is powerful for consistency but creates risk. A template that sets a storage account to public access will create public storage accounts every time it runs.
                            <br><br>
                            I've worked with Azure Policy to enforce guardrailsâ€”preventing certain configurations from being deployed. And tools like Defender for Cloud continuously scan for misconfigurations and compliance drift.
                            <br><br>
                            <strong class="text-emerald-400">Visibility Challenges:</strong>
                            <br><br>
                            On-prem, I could put a network TAP and see all traffic. In cloud, east-west traffic between services often doesn't cross a point where I can inspect it. I rely more on service-level loggingâ€”Azure Activity Logs, diagnostic logs, Azure AD sign-in logsâ€”and correlate them in Sentinel.
                            <br><br>
                            Network Security Groups give me some control and logging at the network layer, but it's not the same as having all traffic flow through a firewall I control.
                            <br><br>
                            <strong class="text-emerald-400">Speed of Change:</strong>
                            <br><br>
                            Cloud environments change faster. Developers can spin up resources in minutes. This is a feature for agility but a bug for security if there's no governance. I've learned to build security into the deployment pipeline rather than trying to audit after the fact.
                            <br><br>
                            <strong class="text-emerald-400">What I've Done Specifically:</strong>
                            <br><br>
                            â€¢ Implemented Azure Policy to enforce tagging standards and prevent public exposure of resources
                            <br>â€¢ Configured Defender for Cloud security recommendations and worked through remediation
                            <br>â€¢ Built Sentinel analytics rules specific to cloud threatsâ€”impossible travel, risky sign-ins, privilege escalation
                            <br>â€¢ Set up Conditional Access policies for Zero Trust approachâ€”device compliance, location-based controls
                            <br>â€¢ Integrated on-prem AD with Azure AD and secured the hybrid identity infrastructure
                            <br><br>
                            The hybrid piece is actually challengingâ€”you have to secure both environments and the connection between them, while managing tools designed for each. That's where my experience with the migration is relevant."
                        </p>
                    </div>
                </div>

                <!-- Analytical/Communication Skills -->
                <div class="technical rounded-xl p-6 mb-6">
                    <p class="text-emerald-400 font-bold mb-4">Q: How do you communicate complex security issues to non-technical stakeholders?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "This is one of the most important skills in security, honestly. You can be the most technically brilliant engineer, but if you can't explain risks to the business, you won't get the support and cooperation you need.
                            <br><br>
                            <strong class="text-emerald-400">Let me give you a real example I deal with regularly:</strong>
                            <br><br>
                            We use Microsoft Defender for Endpoint across our environment, and sometimes an endpoint stops reporting to the console. From my side, I see a device that's gone silentâ€”no telemetry, no health status, nothing. I need to troubleshoot it, but that server or workstation belongs to someone elseâ€”maybe a sysadmin, maybe an end user, maybe someone in a completely different department who has no idea what MDE even is.
                            <br><br>
                            I can't just send an email saying 'Your device isn't sending telemetry to the MDE console. I need to check the SENSE service status and verify connectivity to the cloud endpoints.' That means nothing to them. They'll ignore it or push back because I'm asking for their time without explaining why it matters.
                            <br><br>
                            <strong class="text-emerald-400">Here's how I actually approach it:</strong>
                            <br><br>
                            First, I explain the <strong>why</strong> in terms they care about: 'Hey, I noticed your server has stopped checking in with our security monitoring. This means if something malicious happens on that systemâ€”ransomware, unauthorized access, data theftâ€”we won't see it. We'd be completely blind. It's like having a security camera that's been unplugged without anyone noticing.'
                            <br><br>
                            That analogy clicks for most people. They understand what an unplugged security camera means.
                            <br><br>
                            Then I make the <strong>ask</strong> specific and minimal: 'I need about 15-20 minutes to remote into the system and check a few things. Can we schedule a time where you can let me control your screen? I'll walk you through what I'm doing if you're interested, and I'll make sure I don't disrupt whatever you're working on.'
                            <br><br>
                            By framing it as collaborative rather than demanding, I get much better cooperation. I'm not saying 'give me access now'â€”I'm saying 'let's schedule time that works for you.'
                            <br><br>
                            <strong class="text-emerald-400">During the session</strong>, I explain what I'm checking as I go: 'I'm looking at this service that sends security data to our central console... it looks like it stopped running after the last update. I'm going to restart it and verify it reconnects.' Even if they don't fully understand, they see that I know what I'm doing and I'm not just randomly clicking around their system.
                            <br><br>
                            <strong class="text-emerald-400">After I fix it</strong>, I follow up: 'All setâ€”your system is reporting back to our security console now. If you notice any performance issues or anything unusual, let me know.' This closes the loop and leaves them with a positive impression of working with security.
                            <br><br>
                            <strong class="text-emerald-400">The broader principles I follow:</strong>
                            <br><br>
                            <strong>1. Translate to Business Impact</strong> â€” Nobody cares about 'telemetry' or 'SENSE service.' They care about: Can my system be compromised without anyone knowing? Could I be blamed if something bad happens?
                            <br><br>
                            <strong>2. Use Analogies</strong> â€” Security camera, burglar alarm, locked doorâ€”these physical security concepts translate well. 'Network segmentation' means nothing; 'not giving everyone keys to every room' makes sense instantly.
                            <br><br>
                            <strong>3. Quantify When Possible</strong> â€” 'We blocked 47 data exfiltration attempts last quarter' is more impactful than 'DLP is working.' When I explain why the agent matters, I might say 'Last month this system detected three suspicious activities that we investigatedâ€”without the agent, we'd have missed all of them.'
                            <br><br>
                            <strong>4. Know Your Audience</strong> â€” For a sysadmin, I can be more technical. For an executive assistant whose laptop isn't reporting, I keep it simple. For management, I talk about risk and compliance. Same underlying issue, different framing.
                            <br><br>
                            <strong>5. Make It Easy to Say Yes</strong> â€” 'Can I have 15 minutes at a time convenient for you?' is better than 'I need access to your system.' Reduce friction, respect their time, and they'll cooperate.
                            <br><br>
                            The key is empathyâ€”understanding that this person has their own job to do, and security is an interruption for them. If I make the interaction respectful and efficient, they'll be more cooperative next time too. Security work depends on relationships across the organization."
                        </p>
                    </div>
                </div>

                <!-- Fortinet Specific -->
                <div class="technical rounded-xl p-6 mb-6">
                    <p class="text-emerald-400 font-bold mb-4">Q: The role mentions Fortinet certifications. What's your experience with Fortinet products?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I want to be upfrontâ€”my primary NGFW experience is with Palo Alto, not Fortinet. However, the core concepts transfer directly, and I've made it a point to understand FortiGate because it's so prevalent in the industry.
                            <br><br>
                            <strong class="text-emerald-400">What I know about FortiGate:</strong>
                            <br><br>
                            I understand FortiGate's architectureâ€”the FortiOS operating system, the concept of VDOMs for multi-tenancy, the Security Fabric for integrated security across Fortinet products. I know that FortiGate handles application control, IPS, antivirus, web filtering similar to Palo Alto but with different terminology and interface.
                            <br><br>
                            I've studied the CLI structureâ€”'config firewall policy' versus Palo Alto's 'set rulebase security rules.' The concepts are the same: you're defining source, destination, service, action, and security profiles. The syntax differs.
                            <br><br>
                            FortiGate's approach to UTM is slightly differentâ€”it bundles security features into the firewall policy directly rather than attaching separate security profiles like Palo Alto does. Both achieve the same outcome.
                            <br><br>
                            <strong class="text-emerald-400">Transferable skills:</strong>
                            <br><br>
                            â€¢ NGFW conceptsâ€”App-ID equivalent (application control), user identification, SSL inspection, threat prevention
                            <br>â€¢ Policy designâ€”least privilege, rule ordering, logging configuration
                            <br>â€¢ Troubleshooting methodologyâ€”checking session tables, reviewing logs, understanding traffic flow
                            <br>â€¢ Integrationâ€”SIEM forwarding, AD integration, API usage
                            <br><br>
                            <strong class="text-emerald-400">My learning plan:</strong>
                            <br><br>
                            If this role involves FortiGate, I'm prepared to ramp up quickly. I learn best hands-on, so I'd set up a lab environmentâ€”Fortinet offers free VM trialsâ€”and work through configuration scenarios. The NSE certification path is well-documented, and I'd pursue NSE 4 as a baseline to demonstrate competency.
                            <br><br>
                            I've done vendor transitions beforeâ€”learning Palo Alto after working with different firewalls, learning Microsoft security stack after Trellix. The pattern is: understand the concepts deeply, then learn the specific implementation. I'm confident I can do this with FortiGate."
                        </p>
                    </div>
                </div>

                <!-- Why You Over Others -->
                <div class="behavioral rounded-xl p-6 mb-6">
                    <p class="text-purple-400 font-bold mb-4">Q: Why should we hire you over other candidates?</p>
                    <div class="answer-box">
                        <p class="text-gray-300 text-sm leading-relaxed">
                            "I can't speak to other candidates, but I can tell you what I bring that I think is valuable.
                            <br><br>
                            <strong class="text-emerald-400">I've done the work you're hiring for.</strong>
                            <br><br>
                            This role mentions security technology implementation, DLP, cloud security, SIEM integration, firewalls. I'm not learning these on the jobâ€”I've actively led a DLP migration from Symantec to Purview, built SIEM correlation rules in Sentinel, onboarded endpoints to MDE, and worked with NGFWs for years. The learning curve for your environment will be about specifics, not fundamentals.
                            <br><br>
                            <strong class="text-emerald-400">I can operate at multiple levels.</strong>
                            <br><br>
                            I can get hands-on with PowerShell scripts and KQL queries when needed, but I can also communicate with leadership about risk and business impact. I've navigated organizational dynamicsâ€”convincing skeptical infrastructure teams, coordinating with business units on DLP exceptions, working with compliance on framework requirements. Security engineering isn't just technical; it's also organizational.
                            <br><br>
                            <strong class="text-emerald-400">I'm genuinely passionate about this work.</strong>
                            <br><br>
                            I build security tools in my personal timeâ€”not for a portfolio, but because I'm interested in the problems. The email security platform I mentioned isn't a demo project; real people use it. That curiosity and drive to build things translates into someone who'll proactively identify and solve problems, not just work a ticket queue.
                            <br><br>
                            <strong class="text-emerald-400">I'm at an inflection point in my career.</strong>
                            <br><br>
                            I've completed major projects at my current roleâ€”the DLP migration is nearly done. I'm looking for a new challenge where I can grow. Coca-Cola's scale, the OT security dimension, the global scopeâ€”these are opportunities to expand my skills while contributing meaningfully. I'm motivated to prove myself in a new environment.
                            <br><br>
                            <strong class="text-emerald-400">I'm honest about what I don't know.</strong>
                            <br><br>
                            I haven't done hands-on OT security or managed FortiGate at scale. But I've been transparent about that and explained how I'd ramp up. I'd rather be honest about gaps than oversell and underdeliver. You're getting an accurate picture of what I bring."
                        </p>
                    </div>
                </div>
            </section>

            <!-- ============================================ -->
            <!-- DAILY REVISION -->
            <!-- ============================================ -->
            <section class="mb-16">
                <h2 class="text-2xl font-bold mb-6 text-white flex items-center gap-3">
                    <span class="w-8 h-8 rounded-lg bg-pink-500/20 flex items-center justify-center text-pink-400">19</span>
                    Daily Revision Checklist
                </h2>

                <div class="memorize rounded-xl p-6 mb-4">
                    <h3 class="text-pink-400 font-bold mb-3">ğŸ§  Read Every Day Before Interview</h3>
                    <div class="grid md:grid-cols-3 gap-4 text-sm">
                        <div>
                            <p class="text-white font-medium mb-2">DLP Migration</p>
                            <ul class="text-gray-400 space-y-1">
                                <li>âœ“ Simulation â†’ Audit â†’ Enforcement</li>
                                <li>âœ“ Dual running: Symantec enforce + Purview audit</li>
                                <li>âœ“ SIT confidence tuning</li>
                                <li>âœ“ EDM + contextual logic</li>
                                <li>âœ“ Exceptions: path, process, domain</li>
                                <li>âœ“ Business workflow validation</li>
                                <li>âœ“ Condition-based vs Rule-based</li>
                            </ul>
                        </div>
                        <div>
                            <p class="text-white font-medium mb-2">SIEM/EDR Migration</p>
                            <ul class="text-gray-400 space-y-1">
                                <li>âœ“ RSA â†’ Sentinel KQL conversion</li>
                                <li>âœ“ ESET â†’ MDE with coexistence</li>
                                <li>âœ“ Meta key to table mapping</li>
                                <li>âœ“ MITRE alignment</li>
                                <li>âœ“ Dual-running validation</li>
                                <li>âœ“ Ingestion health workbook</li>
                                <li>âœ“ Logic Apps automation</li>
                            </ul>
                        </div>
                        <div>
                            <p class="text-white font-medium mb-2">Key Stories</p>
                            <ul class="text-gray-400 space-y-1">
                                <li>âœ“ MDE vs ESET conflict</li>
                                <li>âœ“ Onboarding script disagreement</li>
                                <li>âœ“ Senior analyst feedback</li>
                                <li>âœ“ Framework mapping approach</li>
                                <li>âœ“ Why Coca-Cola</li>
                                <li>âœ“ OT interest (honest about learning)</li>
                                <li>âœ“ Finished 3 months early</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <div class="memorize rounded-xl p-6">
                    <h3 class="text-pink-400 font-bold mb-3">ğŸ”§ Technical Deep Dive Quick Reference</h3>
                    <div class="grid md:grid-cols-4 gap-4 text-sm">
                        <div>
                            <p class="text-white font-medium mb-2">NGFW & Cloud</p>
                            <ul class="text-gray-400 space-y-1">
                                <li>âœ“ Change mgmt process</li>
                                <li>âœ“ Asymmetric routing fix</li>
                                <li>âœ“ App-ID + DPI</li>
                                <li>âœ“ NSGs + ASGs</li>
                                <li>âœ“ Azure Policy auditâ†’deny</li>
                                <li>âœ“ IaaS vs PaaS responsibility</li>
                            </ul>
                        </div>
                        <div>
                            <p class="text-white font-medium mb-2">PAM & Identity</p>
                            <ul class="text-gray-400 space-y-1">
                                <li>âœ“ Azure PIM JIT access</li>
                                <li>âœ“ Managed Identities (no creds)</li>
                                <li>âœ“ Key Vault for secrets</li>
                                <li>âœ“ Time-bound role assignments</li>
                                <li>âœ“ Approval workflows</li>
                                <li>âœ“ Break-glass procedures</li>
                            </ul>
                        </div>
                        <div>
                            <p class="text-white font-medium mb-2">Vuln Mgmt & EDR</p>
                            <ul class="text-gray-400 space-y-1">
                                <li>âœ“ Prioritization framework</li>
                                <li>âœ“ Beyond CVSS factors</li>
                                <li>âœ“ OT = passive monitoring</li>
                                <li>âœ“ False positive tuning</li>
                                <li>âœ“ EDR wave-based rollout</li>
                                <li>âœ“ Alert triage workflow</li>
                            </ul>
                        </div>
                        <div>
                            <p class="text-white font-medium mb-2">Frameworks</p>
                            <ul class="text-gray-400 space-y-1">
                                <li>âœ“ One control â†’ many frameworks</li>
                                <li>âœ“ Evidence reuse across audits</li>
                                <li>âœ“ CIS Level 1 vs Level 2</li>
                                <li>âœ“ Golden images hardening</li>
                                <li>âœ“ Security effectiveness > checkbox</li>
                                <li>âœ“ Gap analysis process</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </section>

        </div>
    </main>
<script src="../js/sidebar.js"></script>
</body>
</html>
